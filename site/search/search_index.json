{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"RAG Generation with watsonx.data and Milvus The next-gen watsonx.data lakehouse is designed to overcome the costs and complexities enterprises face. This will be the world\u2019s first and only open data store with multi-engine support that is built for hybrid deployment across your entire ecosystem. IBM watsonx.data is the only lakehouse with multiple query engines allowing you to optimize costs and performance by pairing the right workload with the right engine. Run all workloads from a single pane of glass, eliminating trade-offs with convenience while still improving cost and performance. Deploy anywhere with full support for hybrid-cloud and multi cloud environments. Shared metadata across multiple engines eliminates the need to re-catalog, accelerating time to value while ensuring governance and eliminating costly implementation efforts. Overview This system demonstrates the use of watsonx.data, Milvus, and the use of the IBM Instructlab Granite model to answer questions regarding a variety of topics. The system has a built-in example of creating a RAG prompt from the IBM web site. You can add additional content to the system to try other scenarios with the system. The system is designed around five steps: The watsonx.data product is used to store control information and the raw documents (PDF, Powerpoint, URLs). The Milvus vector database contains vectors that are built from the raw documents stored in the watsonx.data database. A prompt is generated from the question that is supplied by querying the Milvus database for the document segments that best match the request. The prompt is sent to an AI engine to process. This process is done locally in this system using Ollama. Since there are no GPUs in this system, performance will be slow. The answer is returned to the user Start by importing documents, web sites, or articles from Wikipedia into the system. As a starter document, the IBM 2023 annual report summary has been preloaded. You can ask questions about the earnings to see how the LLM answers your question. An example would be to ask the LLM \"What were IBMs earning in 2023\" without using RAG and then ask the question again using RAG . This provides a comparison of the types of responses you may get from an LLM. Once you have imported one or more documents, you must select which ones to vectorize. The documents will be split into chunks which are then stored and vectorized into the Milvus database. These chunks will be used to generate the RAG prompt when you query the LLM. The Query LLM page will provide an interface for asking questions to the LLM. There are additional settings here which lets you change the LLM that is being used (the IBM instructlab/granite-7b-lab model is the default). Each LLM will behave differently so it is often an interesting exercise to try the same questions with different models. You can set whether or not a RAG prompt is generated as part of your query, as well as adjust how many sentence chunks from the vector database will be used to construct the prompt. If you want to try a different LLM, you can use the Add LLM panel to load an LLM found in the Ollama or Hugging Face library. The load step will download the model to the local server and then make it available as an LLM that you can ask questions of. Note the process to download the model may take several minutes. If you find that the system is not being responsive, you may want to check the Diagnostics page to see if the watsonx.data services are running. You can restart many of the services from this dialog. In addition, the Log file may provide more details on what went wrong. Finally, details about this system and the programs that were used to create this are listed in the Support section. Remember that this system does not contain GPUs which limits the performance of the LLM. However, it does provide an environment to try out RAG prompts and observe how different LLMs behave with and without RAG prompts.","title":"RAG Generation with watsonx.data and Milvus"},{"location":"#rag-generation-with-watsonxdata-and-milvus","text":"The next-gen watsonx.data lakehouse is designed to overcome the costs and complexities enterprises face. This will be the world\u2019s first and only open data store with multi-engine support that is built for hybrid deployment across your entire ecosystem. IBM watsonx.data is the only lakehouse with multiple query engines allowing you to optimize costs and performance by pairing the right workload with the right engine. Run all workloads from a single pane of glass, eliminating trade-offs with convenience while still improving cost and performance. Deploy anywhere with full support for hybrid-cloud and multi cloud environments. Shared metadata across multiple engines eliminates the need to re-catalog, accelerating time to value while ensuring governance and eliminating costly implementation efforts.","title":"RAG Generation with watsonx.data and Milvus"},{"location":"#overview","text":"This system demonstrates the use of watsonx.data, Milvus, and the use of the IBM Instructlab Granite model to answer questions regarding a variety of topics. The system has a built-in example of creating a RAG prompt from the IBM web site. You can add additional content to the system to try other scenarios with the system. The system is designed around five steps: The watsonx.data product is used to store control information and the raw documents (PDF, Powerpoint, URLs). The Milvus vector database contains vectors that are built from the raw documents stored in the watsonx.data database. A prompt is generated from the question that is supplied by querying the Milvus database for the document segments that best match the request. The prompt is sent to an AI engine to process. This process is done locally in this system using Ollama. Since there are no GPUs in this system, performance will be slow. The answer is returned to the user Start by importing documents, web sites, or articles from Wikipedia into the system. As a starter document, the IBM 2023 annual report summary has been preloaded. You can ask questions about the earnings to see how the LLM answers your question. An example would be to ask the LLM \"What were IBMs earning in 2023\" without using RAG and then ask the question again using RAG . This provides a comparison of the types of responses you may get from an LLM. Once you have imported one or more documents, you must select which ones to vectorize. The documents will be split into chunks which are then stored and vectorized into the Milvus database. These chunks will be used to generate the RAG prompt when you query the LLM. The Query LLM page will provide an interface for asking questions to the LLM. There are additional settings here which lets you change the LLM that is being used (the IBM instructlab/granite-7b-lab model is the default). Each LLM will behave differently so it is often an interesting exercise to try the same questions with different models. You can set whether or not a RAG prompt is generated as part of your query, as well as adjust how many sentence chunks from the vector database will be used to construct the prompt. If you want to try a different LLM, you can use the Add LLM panel to load an LLM found in the Ollama or Hugging Face library. The load step will download the model to the local server and then make it available as an LLM that you can ask questions of. Note the process to download the model may take several minutes. If you find that the system is not being responsive, you may want to check the Diagnostics page to see if the watsonx.data services are running. You can restart many of the services from this dialog. In addition, the Log file may provide more details on what went wrong. Finally, details about this system and the programs that were used to create this are listed in the Support section. Remember that this system does not contain GPUs which limits the performance of the LLM. However, it does provide an environment to try out RAG prompts and observe how different LLMs behave with and without RAG prompts.","title":"Overview"},{"location":"wxd-acknowledgements/","text":"Acknowledgments Development George Baklarz, Americas Data and AI Technical Sales Testing and Design Feedback Dale McInnis, Americas Data and AI Technical Sales Concept Based on work by Elena M\u00e1rquez and Srajan Dube Milvus Vector Encoding Based on work by Katherine Ciaravalli TechZone Support Special Thanks to Ben Foulkes for supporting this effort in TechZone Support For any questions regarding the lab, including any suggestions, general comments, or bug reports, please contact: George Baklarz baklarz@ca.ibm.com Slack Channel: #watsonx-data-rag-demo We would also appreciate any feedback on the successful use of the lab. Thanks for using watsonx.data and Milvus! George","title":"Acknowledgements"},{"location":"wxd-acknowledgements/#acknowledgments","text":"","title":"Acknowledgments"},{"location":"wxd-acknowledgements/#development","text":"George Baklarz, Americas Data and AI Technical Sales","title":"Development"},{"location":"wxd-acknowledgements/#testing-and-design-feedback","text":"Dale McInnis, Americas Data and AI Technical Sales","title":"Testing and Design Feedback"},{"location":"wxd-acknowledgements/#concept","text":"Based on work by Elena M\u00e1rquez and Srajan Dube","title":"Concept"},{"location":"wxd-acknowledgements/#milvus-vector-encoding","text":"Based on work by Katherine Ciaravalli","title":"Milvus Vector Encoding"},{"location":"wxd-acknowledgements/#techzone-support","text":"Special Thanks to Ben Foulkes for supporting this effort in TechZone","title":"TechZone Support"},{"location":"wxd-acknowledgements/#support","text":"For any questions regarding the lab, including any suggestions, general comments, or bug reports, please contact: George Baklarz baklarz@ca.ibm.com Slack Channel: #watsonx-data-rag-demo We would also appreciate any feedback on the successful use of the lab. Thanks for using watsonx.data and Milvus! George","title":"Support"},{"location":"wxd-demo-diagnostics/","text":"Diagnostics You usually end up in the Diagnostics section because something went wrong with your server. Hopefully one of the sections below will help solve the problem that you are having. There are 9 sections in the diagnostics screen. These sections cover the following topics: Check Presto Connection Check watsonx.data System Restart Presto Restart watsonx.data Restart LLM Service Rebuild Database Add Library Update Software Restart Application Check Presto Connection Press the Check Connection button to determine if a connection can be established with the watsonx.data system. The system will either tell you that the connection is okay, or that the connection timed out. If the connection timed out, you will need to move on to the next step and check if the watsonx.data system is running. Check watsonx.data System If your connection failed (hint, see button above) then something may be wrong with the Presto engine or watsonx.data. You can check to see what services are up and running in our server by pressing the Check Services button. If you find that the Presto instance is missing, restart Presto. If more than one service is missing you will need to restart the watsonx.data services. Restart Presto If you've determined that the Presto service is down, you can use this section to shut down and restart Presto. Press the Restart Presto button to begin the process. The display will show a progress indicator that tracks the Presto startup process. Note that this can take a few minutes to complete. The system will display a success message when the startup has completed. Restart watsonx.data If nothing seems to work (or mote than one service is stopped), you can try stop and restarting all services in the system. This process will take several minutes to complete, but hopefully this will resolve any of the issues you may be having. Start the process by clicking the Restart watsonx.data button. This process will display multiple messages as it stops and starts services. Restarting the watsonx.data services will take several minutes, as will the startup for Presto. Once the process is complete, you should see a successful completion message. Restart LLM Service If the LLM is not being responsive, you may have to restart the service. Clicking the Restart LLM Service button will stop the LLM service, refresh the image, and then restart it. You may want to restart the service if you come across an error loading an LLM which indicates that the LLM manager is out of date. The can occur when an LLM has features which are not currently supported in the LLM manager. Restarting the LLM manager will automatically refresh the image to the latest version available. Rebuild Database If your database is messed up, or corrupted, then you will need to rebuild the database. This will completely remove all the hard work you put into uploading documents so be prepared to do all of that work over again! Press the Rebuild Database button to destroy the existing database and create a new one. The rebuild process will go through several steps to reset the database. The entire process usually takes less than a minute to complete. Add Library This program contains most (not all!) of the conversion libraries required for importing documents into the system. If you encounter an error while importing a document, it may be due to one the conversion library was missing. The first step is to check the Log file and determine what library the system is complaining about. In this example, we tried to vectorize a Microsoft Word file with an extension of .DOCX . Switching to the Log viewer, scrolling to the end we see that the library docx2txt is required for the document to be vectorized. Enter the name of the required library into the library name field and press install Libraries . The system will display a success message when the command completes. You should review the log file to make sure that the installation was successful. Some libraries have multiple requirements and there may be more than one file that gets installed. Always best to check to see the messages in the log file. Now that the library has been loaded, we can attempt to vectorize the document again. Update Software When you deploy an image from TechZone, the latest software for this demonstration program is loaded into the system. If there has been an update (or a fix released for an issue you came across), you can update the software by clicking the Update software button. The current release of the software is shown in the panel. The update process will take several minutes. The first step will download the software and then switch to the Main screen. The system will then update several services in the system and provide a progress indicator: Checking Milvus Checking Presto Removing old collections Insert default documents Updating LLM Engine (not shown) Once the update is complete, the main menu will be displayed. You can check the software level by viewing the Update Software section of the Diagnostic panel. Restart Application Normally, you do not need to restart the application after a software update. However, if you find that you are unable to upload documents (403 code), you may need to restart the application. This will stop the program and restart it. The application will stop responding for a few minutes while the service restarts. When you log back into the application, it will return to the diagnostics screen. If you receive an error code on the screen, continue to refresh the browser until the log in window displays.","title":"Diagnostics"},{"location":"wxd-demo-diagnostics/#diagnostics","text":"You usually end up in the Diagnostics section because something went wrong with your server. Hopefully one of the sections below will help solve the problem that you are having. There are 9 sections in the diagnostics screen. These sections cover the following topics: Check Presto Connection Check watsonx.data System Restart Presto Restart watsonx.data Restart LLM Service Rebuild Database Add Library Update Software Restart Application","title":"Diagnostics"},{"location":"wxd-demo-diagnostics/#check-presto-connection","text":"Press the Check Connection button to determine if a connection can be established with the watsonx.data system. The system will either tell you that the connection is okay, or that the connection timed out. If the connection timed out, you will need to move on to the next step and check if the watsonx.data system is running.","title":"Check Presto Connection"},{"location":"wxd-demo-diagnostics/#check-watsonxdata-system","text":"If your connection failed (hint, see button above) then something may be wrong with the Presto engine or watsonx.data. You can check to see what services are up and running in our server by pressing the Check Services button. If you find that the Presto instance is missing, restart Presto. If more than one service is missing you will need to restart the watsonx.data services.","title":"Check watsonx.data System"},{"location":"wxd-demo-diagnostics/#restart-presto","text":"If you've determined that the Presto service is down, you can use this section to shut down and restart Presto. Press the Restart Presto button to begin the process. The display will show a progress indicator that tracks the Presto startup process. Note that this can take a few minutes to complete. The system will display a success message when the startup has completed.","title":"Restart Presto"},{"location":"wxd-demo-diagnostics/#restart-watsonxdata","text":"If nothing seems to work (or mote than one service is stopped), you can try stop and restarting all services in the system. This process will take several minutes to complete, but hopefully this will resolve any of the issues you may be having. Start the process by clicking the Restart watsonx.data button. This process will display multiple messages as it stops and starts services. Restarting the watsonx.data services will take several minutes, as will the startup for Presto. Once the process is complete, you should see a successful completion message.","title":"Restart watsonx.data"},{"location":"wxd-demo-diagnostics/#restart-llm-service","text":"If the LLM is not being responsive, you may have to restart the service. Clicking the Restart LLM Service button will stop the LLM service, refresh the image, and then restart it. You may want to restart the service if you come across an error loading an LLM which indicates that the LLM manager is out of date. The can occur when an LLM has features which are not currently supported in the LLM manager. Restarting the LLM manager will automatically refresh the image to the latest version available.","title":"Restart LLM Service"},{"location":"wxd-demo-diagnostics/#rebuild-database","text":"If your database is messed up, or corrupted, then you will need to rebuild the database. This will completely remove all the hard work you put into uploading documents so be prepared to do all of that work over again! Press the Rebuild Database button to destroy the existing database and create a new one. The rebuild process will go through several steps to reset the database. The entire process usually takes less than a minute to complete.","title":"Rebuild Database"},{"location":"wxd-demo-diagnostics/#add-library","text":"This program contains most (not all!) of the conversion libraries required for importing documents into the system. If you encounter an error while importing a document, it may be due to one the conversion library was missing. The first step is to check the Log file and determine what library the system is complaining about. In this example, we tried to vectorize a Microsoft Word file with an extension of .DOCX . Switching to the Log viewer, scrolling to the end we see that the library docx2txt is required for the document to be vectorized. Enter the name of the required library into the library name field and press install Libraries . The system will display a success message when the command completes. You should review the log file to make sure that the installation was successful. Some libraries have multiple requirements and there may be more than one file that gets installed. Always best to check to see the messages in the log file. Now that the library has been loaded, we can attempt to vectorize the document again.","title":"Add Library"},{"location":"wxd-demo-diagnostics/#update-software","text":"When you deploy an image from TechZone, the latest software for this demonstration program is loaded into the system. If there has been an update (or a fix released for an issue you came across), you can update the software by clicking the Update software button. The current release of the software is shown in the panel. The update process will take several minutes. The first step will download the software and then switch to the Main screen. The system will then update several services in the system and provide a progress indicator: Checking Milvus Checking Presto Removing old collections Insert default documents Updating LLM Engine (not shown) Once the update is complete, the main menu will be displayed. You can check the software level by viewing the Update Software section of the Diagnostic panel.","title":"Update Software"},{"location":"wxd-demo-diagnostics/#restart-application","text":"Normally, you do not need to restart the application after a software update. However, if you find that you are unable to upload documents (403 code), you may need to restart the application. This will stop the program and restart it. The application will stop responding for a few minutes while the service restarts. When you log back into the application, it will return to the diagnostics screen. If you receive an error code on the screen, continue to refresh the browser until the log in window displays.","title":"Restart Application"},{"location":"wxd-demo-examples/","text":"Sample LLM Queries This section includes some sample LLM queries and the results. One thing to note is that if you attempt these examples, the output can be different than what is shown here. The reason for this is that LLMs are not deterministic which means the same question can result in different answers. Hopefully in our case, the answers are similar! If you want to get repeatable results for the questions, make sure to set the Random Seed setting to OFF: To display the settings used for each query, turn the Display Settings on. This will place a line below each question with the settings used to generate the prompt to the LLM. For each example, note the settings that are used. These settings will displayed in each section. LLM Use RAG Prompt Display RAG Prompt Concise Response Sentences granite-7b-lab \u2705 \u2705 \u274c 3 Question with no RAG Support The first example will ask the LLM the question with all settings turned off. LLM Use RAG Prompt Display RAG Prompt Concise Response Sentences granite-7b-lab \u274c \u274c \u274c - Question What is IBMs 2023 revenue. Answer As a helpful AI assistant, I don't have real-time access to the internet or proprietary company information, so I can't provide you with the exact 2023 revenue of IBM. However, I can give you some context about IBM's financial performance and how to find this information officially. IBM is a multinational technology corporation that provides various products and services, including hardware, software, cloud, consulting, and support. The company releases its annual reports and financial statements, which contain detailed revenue information for different segments and geographical regions. To access IBM's 2023 revenue, I recommend visiting the official IBM investor relations website (https://www.ibm.com/investor/reports-and-presentations) or the Securities and Exchange Commission (SEC) filings database (https://www.sec.gov/). These resources will provide you with the most accurate and up-to-date financial information about IBM, including its revenue for the year 2023, once it is officially released. Analysis The LLM does not have the information for 2023 results and provided us with an answer on how to get the results we want. Question with no RAG Support but Concise Response The first example let the LLM display as much output as it wanted. In this example, the Concise Response is turned on, as well as the Display RAG prompt,so you can see how the program modified the question. LLM Use RAG Prompt Display RAG Prompt Concise Response Sentences granite-7b-lab \u2705 \u274c \u2705 - Question Provide a concise response to this prompt: What is IBMs 2023 revenue? Answer As an AI language model, I don't have real-time capabilities or access to current, confidential, or proprietary information from IBM or any other organizations. I cannot provide the exact 2023 revenue for IBM. For accurate financial data, I encourage you to consult IBM's official financial statements or trusted business resources. Analysis You can limit the amount of output from the LLM by turning on the concise flag. While this will speed up the processing of the question by the LLM, it may reduce the amount of useful information that you get back. Question with RAG On, Concise On, RAG Display, and 3 Sentences The question that we ask the LLM will now use RAG to generate it. The document collection that is being used is called IBM_2023_Annual_Report and contains the summary of the IBM 2023 earning report. LLM Use RAG Prompt Display RAG Prompt Concise Response Sentences granite-7b-lab \u2705 \u2705 \u2705 3 Question Answer the question based on the context below. If the question cannot be answered using the information provided answer with \"I don't know\". Context: Todays IBM is more capable and more productive. We have a strong portfolio and a solid foundation to support sustainable growth. And we are delivering on our promise to be the catalyst that makes the world work better. 2023 performance For the year, IBM generated $61.9 billion in revenue, up 3% at constant currency, and $11.2 billion of free cash flow, up $1.9 billion year-over-year. We experienced growing demand for our new watsonx platform, marked by thousands of client Infrastructure revenues decreased by 4% at constant currency, in line with the typical product cycle dynamics in this segment. IBM z16 is significantly outperforming previous cycles, demonstrating the enduring value this platform provides to our clients. IBMs revenue growth and cash generation enabled us to make substantial investments in the business and deliver value to our shareholders. In 2023, IBM spent nearly $7 billion on research and IBM spent nearly $7 billion on research and development, more than $5 billion to acquire nine companies, and returned more than $6 billion to stockholders through dividends. small arrow software Software consulting Consulting infrastructure Infrastructure Technology and expertise AI and hybrid cloud continue to drive value creation, allowing businesses to scale,. Question: Provide a concise response to What is IBMs 2023 revenue? Answer IBM's 2023 revenue was $61.9 billion, as stated in the context. Analysis The LLM provides the correct response. The generated RAG prompt contains sentences from the earnings report that most closely match the original question. You will note that several of the paragraphs are not complete and may contain special characters that are not seen on the screen. The reason for incomplete sentences is that the vectors are created by taking tokens (loosely translated to words) until they equal a set number of vectors. Vectors need to be of equal distance in order to do valid comparisons. For this reason, you tend to get sentences that are not complete. Question with Incorrect Context If you use an incorrect document collection, or ask a question which is not covered by the RAG that is generated, you will either get an answer of \"I don't know\" or something unexpected. For this example we turn off the RAG display and allow for unrestricted output. LLM Use RAG Prompt Display RAG Prompt Concise Response Sentences granite-7b-lab \u2705 \u274c \u274c 3 Question What is the color of the IBM logo? Answer I'm sorry for any confusion, but the information provided in the context does not include details about the color of the IBM logo. I cannot accurately answer this question with the given context. Analysis As expected, the LLM was unable to answer the question based on the information provided to it. If we turn off RAG generation, the LLM will answer the question properly. LLM Use RAG Prompt Display RAG Prompt Concise Response Sentences granite-7b-lab \u274c \u274c \u274c - Question What is the color of the IBM logo? Answer The IBM logo is primarily a blue color, specifically a shade of Navy Blue (Pantone 285C). This blue hue is often associated with trust, stability, and confidence. However, it's important to note that the IBM logo also incorporates white and black elements, which contribute to its overall simplicity and clarity. The white space in the logo helps to balance the blue and black, making it easily recognizable and distinguishable on various backgrounds. Overall, the IBM logo is a well-designed and versatile emblem that effectively represents the company's identity and values. Question using phi3 LLM If you are curious what another LLM would say about the logo, you can switch the LLM setting found on the left toolbar and repeat the question. LLM Use RAG Prompt Display RAG Prompt Concise Response Sentences phi3:3.8b-mini-128k \u274c \u274c \u274c - Question What is the color of the IBM logo? Answer The color scheme for the IBM (International Business Machines Corporation) logo has undergone various changes since its inception. The most recognizable version today, first introduced in 1972 by graphic designer Paul Rand and known as \"Blue Intrigue,\" features a blue oval with rounded corners. Within this blue space is the corporate name: International Business Machines Corporation (IBM). There are no specific colors associated that aren't part of the overall color scheme, which remains primarily in shades of dark blues complemented by white text and accents against other company branding materials for consistency with their global market presence. Analysis Paul Rand did introduce the 8-bar IBM logo in 1972 and has created many other logos during his career. To view more logos see Paul Rand Design . Question using other LLMs You can switch between different LLMs to determine how these models deal with the same questions. This first example will use the llama3 LLM and ask what IBM's 2023 revenue was (no RAG). LLM Use RAG Prompt Display RAG Prompt Concise Response Sentences llama3 \u274c \u274c \u274c - Question What is IBMs 2023 revenue? Answer According to IBM's quarterly and annual earnings reports, here are the company's revenues for each quarter of 2022 and 2021: 2022: Q1 (January-March): $16.7 billion Q2 (April-June): $15.8 billion Q3 (July-September): $17.6 billion Q4 (October-December): $20.5 billion 2021: Q1 (January-March): $19.2 billion Q2 (April-June): $16.7 billion Q3 (July-September): $18.3 billion Q4 (October-December): $21.8 billion As for the full-year 2022 revenue, IBM reported: 2022: $79.6 billion For comparison, IBM's full-year 2021 revenue was $75.7 billion. Please note that these figures are subject to change and might not reflect any subsequent revisions or updates made by IBM. Analysis The LLM did not answer the question directly. Instead, it provided information for previous years. The next answer is based on using a RAG prompt. LLM Use RAG Prompt Display RAG Prompt Concise Response Sentences llama3 \u2705 \u274c \u2705 3 Question What is IBMs 2023 revenue? Answer IBM's 2023 revenue was $61.9 billion, up 3% at constant currency. Analysis The LLM was able to use the RAG details to provide an accurate answer to the question. Additional Questions Here are some sample questions you may want to try with different LLMs to see how they answer them. What are the top areas of revenue growth in 2023 for IBM? Who is the CEO of IBM? What is IBMs focus in the area of AI? Does the z processor still have relevance in IBM? What investment does IBM have in quantum computing?\u00df If you find that an LLM is unable to provide an answer \u201cbased on the context provided\u201d, you may need to increase the number of sentences used to generate the RAG response. Try the following question using 3 and then 9 sentences. Turn off Display RAG Prompt to minimize the amount of output on the screen. Which area in IBM saw decreased revenues in 2023?","title":"Sample LLM Queries"},{"location":"wxd-demo-examples/#sample-llm-queries","text":"This section includes some sample LLM queries and the results. One thing to note is that if you attempt these examples, the output can be different than what is shown here. The reason for this is that LLMs are not deterministic which means the same question can result in different answers. Hopefully in our case, the answers are similar! If you want to get repeatable results for the questions, make sure to set the Random Seed setting to OFF: To display the settings used for each query, turn the Display Settings on. This will place a line below each question with the settings used to generate the prompt to the LLM. For each example, note the settings that are used. These settings will displayed in each section. LLM Use RAG Prompt Display RAG Prompt Concise Response Sentences granite-7b-lab \u2705 \u2705 \u274c 3","title":"Sample LLM Queries"},{"location":"wxd-demo-examples/#question-with-no-rag-support","text":"The first example will ask the LLM the question with all settings turned off. LLM Use RAG Prompt Display RAG Prompt Concise Response Sentences granite-7b-lab \u274c \u274c \u274c -","title":"Question with no RAG Support"},{"location":"wxd-demo-examples/#question","text":"What is IBMs 2023 revenue.","title":"Question"},{"location":"wxd-demo-examples/#answer","text":"As a helpful AI assistant, I don't have real-time access to the internet or proprietary company information, so I can't provide you with the exact 2023 revenue of IBM. However, I can give you some context about IBM's financial performance and how to find this information officially. IBM is a multinational technology corporation that provides various products and services, including hardware, software, cloud, consulting, and support. The company releases its annual reports and financial statements, which contain detailed revenue information for different segments and geographical regions. To access IBM's 2023 revenue, I recommend visiting the official IBM investor relations website (https://www.ibm.com/investor/reports-and-presentations) or the Securities and Exchange Commission (SEC) filings database (https://www.sec.gov/). These resources will provide you with the most accurate and up-to-date financial information about IBM, including its revenue for the year 2023, once it is officially released.","title":"Answer"},{"location":"wxd-demo-examples/#analysis","text":"The LLM does not have the information for 2023 results and provided us with an answer on how to get the results we want.","title":"Analysis"},{"location":"wxd-demo-examples/#question-with-no-rag-support-but-concise-response","text":"The first example let the LLM display as much output as it wanted. In this example, the Concise Response is turned on, as well as the Display RAG prompt,so you can see how the program modified the question. LLM Use RAG Prompt Display RAG Prompt Concise Response Sentences granite-7b-lab \u2705 \u274c \u2705 -","title":"Question with no RAG Support but Concise Response"},{"location":"wxd-demo-examples/#question_1","text":"Provide a concise response to this prompt: What is IBMs 2023 revenue?","title":"Question"},{"location":"wxd-demo-examples/#answer_1","text":"As an AI language model, I don't have real-time capabilities or access to current, confidential, or proprietary information from IBM or any other organizations. I cannot provide the exact 2023 revenue for IBM. For accurate financial data, I encourage you to consult IBM's official financial statements or trusted business resources.","title":"Answer"},{"location":"wxd-demo-examples/#analysis_1","text":"You can limit the amount of output from the LLM by turning on the concise flag. While this will speed up the processing of the question by the LLM, it may reduce the amount of useful information that you get back.","title":"Analysis"},{"location":"wxd-demo-examples/#question-with-rag-on-concise-on-rag-display-and-3-sentences","text":"The question that we ask the LLM will now use RAG to generate it. The document collection that is being used is called IBM_2023_Annual_Report and contains the summary of the IBM 2023 earning report. LLM Use RAG Prompt Display RAG Prompt Concise Response Sentences granite-7b-lab \u2705 \u2705 \u2705 3","title":"Question with RAG On, Concise On, RAG Display, and 3 Sentences"},{"location":"wxd-demo-examples/#question_2","text":"Answer the question based on the context below. If the question cannot be answered using the information provided answer with \"I don't know\". Context: Todays IBM is more capable and more productive. We have a strong portfolio and a solid foundation to support sustainable growth. And we are delivering on our promise to be the catalyst that makes the world work better. 2023 performance For the year, IBM generated $61.9 billion in revenue, up 3% at constant currency, and $11.2 billion of free cash flow, up $1.9 billion year-over-year. We experienced growing demand for our new watsonx platform, marked by thousands of client Infrastructure revenues decreased by 4% at constant currency, in line with the typical product cycle dynamics in this segment. IBM z16 is significantly outperforming previous cycles, demonstrating the enduring value this platform provides to our clients. IBMs revenue growth and cash generation enabled us to make substantial investments in the business and deliver value to our shareholders. In 2023, IBM spent nearly $7 billion on research and IBM spent nearly $7 billion on research and development, more than $5 billion to acquire nine companies, and returned more than $6 billion to stockholders through dividends. small arrow software Software consulting Consulting infrastructure Infrastructure Technology and expertise AI and hybrid cloud continue to drive value creation, allowing businesses to scale,. Question: Provide a concise response to What is IBMs 2023 revenue?","title":"Question"},{"location":"wxd-demo-examples/#answer_2","text":"IBM's 2023 revenue was $61.9 billion, as stated in the context.","title":"Answer"},{"location":"wxd-demo-examples/#analysis_2","text":"The LLM provides the correct response. The generated RAG prompt contains sentences from the earnings report that most closely match the original question. You will note that several of the paragraphs are not complete and may contain special characters that are not seen on the screen. The reason for incomplete sentences is that the vectors are created by taking tokens (loosely translated to words) until they equal a set number of vectors. Vectors need to be of equal distance in order to do valid comparisons. For this reason, you tend to get sentences that are not complete.","title":"Analysis"},{"location":"wxd-demo-examples/#question-with-incorrect-context","text":"If you use an incorrect document collection, or ask a question which is not covered by the RAG that is generated, you will either get an answer of \"I don't know\" or something unexpected. For this example we turn off the RAG display and allow for unrestricted output. LLM Use RAG Prompt Display RAG Prompt Concise Response Sentences granite-7b-lab \u2705 \u274c \u274c 3","title":"Question with Incorrect Context"},{"location":"wxd-demo-examples/#question_3","text":"What is the color of the IBM logo?","title":"Question"},{"location":"wxd-demo-examples/#answer_3","text":"I'm sorry for any confusion, but the information provided in the context does not include details about the color of the IBM logo. I cannot accurately answer this question with the given context.","title":"Answer"},{"location":"wxd-demo-examples/#analysis_3","text":"As expected, the LLM was unable to answer the question based on the information provided to it. If we turn off RAG generation, the LLM will answer the question properly. LLM Use RAG Prompt Display RAG Prompt Concise Response Sentences granite-7b-lab \u274c \u274c \u274c -","title":"Analysis"},{"location":"wxd-demo-examples/#question_4","text":"What is the color of the IBM logo?","title":"Question"},{"location":"wxd-demo-examples/#answer_4","text":"The IBM logo is primarily a blue color, specifically a shade of Navy Blue (Pantone 285C). This blue hue is often associated with trust, stability, and confidence. However, it's important to note that the IBM logo also incorporates white and black elements, which contribute to its overall simplicity and clarity. The white space in the logo helps to balance the blue and black, making it easily recognizable and distinguishable on various backgrounds. Overall, the IBM logo is a well-designed and versatile emblem that effectively represents the company's identity and values.","title":"Answer"},{"location":"wxd-demo-examples/#question-using-phi3-llm","text":"If you are curious what another LLM would say about the logo, you can switch the LLM setting found on the left toolbar and repeat the question. LLM Use RAG Prompt Display RAG Prompt Concise Response Sentences phi3:3.8b-mini-128k \u274c \u274c \u274c -","title":"Question using phi3 LLM"},{"location":"wxd-demo-examples/#question_5","text":"What is the color of the IBM logo?","title":"Question"},{"location":"wxd-demo-examples/#answer_5","text":"The color scheme for the IBM (International Business Machines Corporation) logo has undergone various changes since its inception. The most recognizable version today, first introduced in 1972 by graphic designer Paul Rand and known as \"Blue Intrigue,\" features a blue oval with rounded corners. Within this blue space is the corporate name: International Business Machines Corporation (IBM). There are no specific colors associated that aren't part of the overall color scheme, which remains primarily in shades of dark blues complemented by white text and accents against other company branding materials for consistency with their global market presence.","title":"Answer"},{"location":"wxd-demo-examples/#analysis_4","text":"Paul Rand did introduce the 8-bar IBM logo in 1972 and has created many other logos during his career. To view more logos see Paul Rand Design .","title":"Analysis"},{"location":"wxd-demo-examples/#question-using-other-llms","text":"You can switch between different LLMs to determine how these models deal with the same questions. This first example will use the llama3 LLM and ask what IBM's 2023 revenue was (no RAG). LLM Use RAG Prompt Display RAG Prompt Concise Response Sentences llama3 \u274c \u274c \u274c -","title":"Question using other LLMs"},{"location":"wxd-demo-examples/#question_6","text":"What is IBMs 2023 revenue?","title":"Question"},{"location":"wxd-demo-examples/#answer_6","text":"According to IBM's quarterly and annual earnings reports, here are the company's revenues for each quarter of 2022 and 2021: 2022: Q1 (January-March): $16.7 billion Q2 (April-June): $15.8 billion Q3 (July-September): $17.6 billion Q4 (October-December): $20.5 billion 2021: Q1 (January-March): $19.2 billion Q2 (April-June): $16.7 billion Q3 (July-September): $18.3 billion Q4 (October-December): $21.8 billion As for the full-year 2022 revenue, IBM reported: 2022: $79.6 billion For comparison, IBM's full-year 2021 revenue was $75.7 billion. Please note that these figures are subject to change and might not reflect any subsequent revisions or updates made by IBM.","title":"Answer"},{"location":"wxd-demo-examples/#analysis_5","text":"The LLM did not answer the question directly. Instead, it provided information for previous years. The next answer is based on using a RAG prompt. LLM Use RAG Prompt Display RAG Prompt Concise Response Sentences llama3 \u2705 \u274c \u2705 3","title":"Analysis"},{"location":"wxd-demo-examples/#question_7","text":"What is IBMs 2023 revenue?","title":"Question"},{"location":"wxd-demo-examples/#answer_7","text":"IBM's 2023 revenue was $61.9 billion, up 3% at constant currency.","title":"Answer"},{"location":"wxd-demo-examples/#analysis_6","text":"The LLM was able to use the RAG details to provide an accurate answer to the question.","title":"Analysis"},{"location":"wxd-demo-examples/#additional-questions","text":"Here are some sample questions you may want to try with different LLMs to see how they answer them. What are the top areas of revenue growth in 2023 for IBM? Who is the CEO of IBM? What is IBMs focus in the area of AI? Does the z processor still have relevance in IBM? What investment does IBM have in quantum computing?\u00df If you find that an LLM is unable to provide an answer \u201cbased on the context provided\u201d, you may need to increase the number of sentences used to generate the RAG response. Try the following question using 3 and then 9 sentences. Turn off Display RAG Prompt to minimize the amount of output on the screen. Which area in IBM saw decreased revenues in 2023?","title":"Additional Questions"},{"location":"wxd-demo-import/","text":"Document Import and Storage This system requires that you upload documents or URLs to be used for RAG generation. There is one document (IBM 2023 earnings report summary) provided in the system that you can use for your queries. You have the option of uploading documents from your workstation (PDF, PPT, TXT) and having it cataloged in watsonx.data. You can also point to a website (URL) which will be analyzed, and the contents extracted and stored in watsonx.data. Note that the system does not do a web crawl through all links in the web page, but only captures the text on the web page itself. Finally, you can query Wikipedia and retrieve documents based on a topic. Document Storage The Document storage panel contains three sections in it: Document list Upload Document or URL Upload Wikipedia Articles Document List The document list provides the list of documents that are already stored in the system. The IBM 2023 earnings documents are pre-populated in the system for you to use in the LLM queries. The document display provides the name of the document or URL, and the document type. The document type is determined by the original document file type. Upload Document or URL The Upload dialog provides a way of uploading a document from your workstation or by uploading the contents of a URL. For local files, you can either drag and drop a file from your workstation into the dialog, or press the Browse Files button to display your local file browser (Mac OSX shown). Once the file has been selected, it will be display below the drag and drop line. You can only upload one document at a time. If you have a URL that you want to input into the system, type or paste the URL into the dialog. Once you have selected the file or URL that you want to upload, press the Upload Doc/URL button to start the upload process. A progress indicator will appear while the document is being uploaded. When the upload completes, a success (or failure!) message will be displayed. The document list at the top of the screen will not be updated to reflect the new document until you press the Refresh List button. URL Scraping Make sure that if you decide to use a web page as a source for your RAG examples, that it does not violate any copuright or privacy policies associated with the web page. Upload Wikipedia Documents The bottom of the Document import panel contains an option to search Wikipedia articles for possible documents to use in a RAG prompt. Enter a phrase to search for (watsonx is shown here) and press the Get Articles button. You will see a maximum of 10 documents that were found. In this example, 7 documents related to \"watsonx\" were found in Wikipedia articles. Select which articles you want to load into the system. You can select as many as you want, and they will be combined into a single document in the system. Once you are done selecting the documents, press the Upload button and a progress indicator will display the progress of retrieving the articles. Once the files have been uploaded, a message will be displayed. In the Document display, the wiki article names are concatenated together, and the file type is shown as \"wiki\". Technical Details Documents and the contents of web pages are stored in watsonx.data. There are two Iceberg tables within watsonx.data that store details of the documents. The first table contains document metadata: CREATE TABLE iceberg_data . documents . metadata ( \"id\" int , \"document\" varchar , \"type\" varchar ) This simple table tracks the document name (or URL) along with the type of document. The type of document will determine what routine will be used to extract the text from the contents. The second table contains the data from the document. CREATE TABLE iceberg_data . documents . rawdata ( \"id\" int , \"chunk_id\" int , \"chunk\" varchar ) The data is split into approximately 1M base64 chunks. The reason for the chunking of the data is due to a Presto client limit of 1M messages. Once the data is stored in watsonx.data, access to the underlying object can be controlled through user and group authentication. The data is read and converted to BASE64 format and stored into a VARCHAR field. Upon retrieval, the document is rebuilt back into its' native format. Wiki files that were loaded into the system are always extracted as text files. An alternate strategy to storing documents would be to upload the document and store it in an S3-like bucket. The downside is that the document is exposed in the bucket rather than obfuscated in Iceberg table format. Web Pages Regular documents are stored \"as-is\" in watsonx.data, but URLs are handled differently. A web scraping routine extracts the text from the website and stores it in watsonx.data as a text document. What this means is that the data watsonx.data is valid as of the time the URL was uploaded. If the web page changes, it will not be reflected in the stored document. The web scraping program only retrieves the contents of the URL that was provided and does not traverse down any other links that may be on the web page. Wiki Pages The program uses a Wikipedia API to retrieve articles that match the supplied keywords. Once you select which documents you want included in the system, the program will request the full contents of the document(s) from Wikipedia. The documents are concatenated together to create one text document in the database. Pre-loaded Documents There is one document that has been pre-loaded into the system for your use (2023 IBM Annual Report). You can choose to upload your own documents to use with the LLMs. Some observations regarding documents. PDFs, DOCs, and Text create good RAG prompts with a minimum of 3 sentences PPTs require much more time to extract text and require more sentences (>5) to generate useful RAG prompts URLs generate RAG prompts that may contain images or gifs that are ignored","title":"Import Documents"},{"location":"wxd-demo-import/#document-import-and-storage","text":"This system requires that you upload documents or URLs to be used for RAG generation. There is one document (IBM 2023 earnings report summary) provided in the system that you can use for your queries. You have the option of uploading documents from your workstation (PDF, PPT, TXT) and having it cataloged in watsonx.data. You can also point to a website (URL) which will be analyzed, and the contents extracted and stored in watsonx.data. Note that the system does not do a web crawl through all links in the web page, but only captures the text on the web page itself. Finally, you can query Wikipedia and retrieve documents based on a topic.","title":"Document Import and Storage"},{"location":"wxd-demo-import/#document-storage","text":"The Document storage panel contains three sections in it: Document list Upload Document or URL Upload Wikipedia Articles","title":"Document Storage"},{"location":"wxd-demo-import/#document-list","text":"The document list provides the list of documents that are already stored in the system. The IBM 2023 earnings documents are pre-populated in the system for you to use in the LLM queries. The document display provides the name of the document or URL, and the document type. The document type is determined by the original document file type.","title":"Document List"},{"location":"wxd-demo-import/#upload-document-or-url","text":"The Upload dialog provides a way of uploading a document from your workstation or by uploading the contents of a URL. For local files, you can either drag and drop a file from your workstation into the dialog, or press the Browse Files button to display your local file browser (Mac OSX shown). Once the file has been selected, it will be display below the drag and drop line. You can only upload one document at a time. If you have a URL that you want to input into the system, type or paste the URL into the dialog. Once you have selected the file or URL that you want to upload, press the Upload Doc/URL button to start the upload process. A progress indicator will appear while the document is being uploaded. When the upload completes, a success (or failure!) message will be displayed. The document list at the top of the screen will not be updated to reflect the new document until you press the Refresh List button. URL Scraping Make sure that if you decide to use a web page as a source for your RAG examples, that it does not violate any copuright or privacy policies associated with the web page.","title":"Upload Document or URL"},{"location":"wxd-demo-import/#upload-wikipedia-documents","text":"The bottom of the Document import panel contains an option to search Wikipedia articles for possible documents to use in a RAG prompt. Enter a phrase to search for (watsonx is shown here) and press the Get Articles button. You will see a maximum of 10 documents that were found. In this example, 7 documents related to \"watsonx\" were found in Wikipedia articles. Select which articles you want to load into the system. You can select as many as you want, and they will be combined into a single document in the system. Once you are done selecting the documents, press the Upload button and a progress indicator will display the progress of retrieving the articles. Once the files have been uploaded, a message will be displayed. In the Document display, the wiki article names are concatenated together, and the file type is shown as \"wiki\".","title":"Upload Wikipedia Documents"},{"location":"wxd-demo-import/#technical-details","text":"Documents and the contents of web pages are stored in watsonx.data. There are two Iceberg tables within watsonx.data that store details of the documents. The first table contains document metadata: CREATE TABLE iceberg_data . documents . metadata ( \"id\" int , \"document\" varchar , \"type\" varchar ) This simple table tracks the document name (or URL) along with the type of document. The type of document will determine what routine will be used to extract the text from the contents. The second table contains the data from the document. CREATE TABLE iceberg_data . documents . rawdata ( \"id\" int , \"chunk_id\" int , \"chunk\" varchar ) The data is split into approximately 1M base64 chunks. The reason for the chunking of the data is due to a Presto client limit of 1M messages. Once the data is stored in watsonx.data, access to the underlying object can be controlled through user and group authentication. The data is read and converted to BASE64 format and stored into a VARCHAR field. Upon retrieval, the document is rebuilt back into its' native format. Wiki files that were loaded into the system are always extracted as text files. An alternate strategy to storing documents would be to upload the document and store it in an S3-like bucket. The downside is that the document is exposed in the bucket rather than obfuscated in Iceberg table format.","title":"Technical Details"},{"location":"wxd-demo-import/#web-pages","text":"Regular documents are stored \"as-is\" in watsonx.data, but URLs are handled differently. A web scraping routine extracts the text from the website and stores it in watsonx.data as a text document. What this means is that the data watsonx.data is valid as of the time the URL was uploaded. If the web page changes, it will not be reflected in the stored document. The web scraping program only retrieves the contents of the URL that was provided and does not traverse down any other links that may be on the web page.","title":"Web Pages"},{"location":"wxd-demo-import/#wiki-pages","text":"The program uses a Wikipedia API to retrieve articles that match the supplied keywords. Once you select which documents you want included in the system, the program will request the full contents of the document(s) from Wikipedia. The documents are concatenated together to create one text document in the database.","title":"Wiki Pages"},{"location":"wxd-demo-import/#pre-loaded-documents","text":"There is one document that has been pre-loaded into the system for your use (2023 IBM Annual Report). You can choose to upload your own documents to use with the LLMs. Some observations regarding documents. PDFs, DOCs, and Text create good RAG prompts with a minimum of 3 sentences PPTs require much more time to extract text and require more sentences (>5) to generate useful RAG prompts URLs generate RAG prompts that may contain images or gifs that are ignored","title":"Pre-loaded Documents"},{"location":"wxd-demo-intro/","text":"System Overview This system demonstrates the use of watsonx.data, Milvus, and the use of the IBM Instructlab Granite model to answer questions regarding a variety of topics. The system has a built-in example of creating a RAG prompt from the IBM web site. You can add additional content to the system to try other scenarios with the system. The system is designed around five steps: The watsonx.data product is used to store control information and the raw documents (PDF, Powerpoint, URLs). The Milvus vector database contains vectors that are built from the raw documents stored in the watsonx.data database. A prompt is generated from the question that is supplied by querying the Milvus database for the document segments that best match the request. The prompt is sent to an AI engine to process. This process is done locally in this system using Ollama. Since there are no GPUs in this system, performance will be slow. The answer is returned to the user Start by importing documents, web sites, or articles from Wikipedia into the system. As a starter document, the IBM 2023 annual report web page has been preloaded. You can ask questions about the earnings to see how the LLM answers your question. An example would be to ask the LLM \"What were IBMs earning in 2023\" without using RAG and then ask the question again using RAG . This provides a comparison of the types of responses you may get from an LLM. Once you have imported one or more documents, you must select which ones to vectorize. The documents will be split into chunks which are then stored and vectorized into the Milvus database. These chunks will be used to generate the RAG prompt when you query the LLM. The Query LLM page will provide an interface for asking questions to the LLM. There are additional settings here which lets you change the LLM that is being used (the IBM instructlab/granite-7b-lab model is the default). Each LLM will behave differently so it is often an interesting exercise to try the same questions with different models. You can set whether or not a RAG prompt is generated as part of your query, as well as adjust how many sentence chunks from the vector database will be used to construct the prompt. If you want to try a different LLM, you can use the Add LLM panel to load an LLM found in the Ollama or Hugging Face library. The load step will download the model to the local server and then make it available as an LLM that you can ask questions of. If you find that the system is not being responsive, you may want to check the Diagnostics page to see if the watsonx.data services are running. You can restart many of the services from this dialog. In addition, the Log file may provide more details on what went wrong. Finally, details about this system and the programs that were used to create this are listed in the Support section. Remember that this system does not contain GPUs which limits the performance of the LLM. However, it does provide an environment to try out RAG prompts and observe how different LLMs behave with and without RAG prompts.","title":"Overview"},{"location":"wxd-demo-intro/#system-overview","text":"This system demonstrates the use of watsonx.data, Milvus, and the use of the IBM Instructlab Granite model to answer questions regarding a variety of topics. The system has a built-in example of creating a RAG prompt from the IBM web site. You can add additional content to the system to try other scenarios with the system. The system is designed around five steps: The watsonx.data product is used to store control information and the raw documents (PDF, Powerpoint, URLs). The Milvus vector database contains vectors that are built from the raw documents stored in the watsonx.data database. A prompt is generated from the question that is supplied by querying the Milvus database for the document segments that best match the request. The prompt is sent to an AI engine to process. This process is done locally in this system using Ollama. Since there are no GPUs in this system, performance will be slow. The answer is returned to the user Start by importing documents, web sites, or articles from Wikipedia into the system. As a starter document, the IBM 2023 annual report web page has been preloaded. You can ask questions about the earnings to see how the LLM answers your question. An example would be to ask the LLM \"What were IBMs earning in 2023\" without using RAG and then ask the question again using RAG . This provides a comparison of the types of responses you may get from an LLM. Once you have imported one or more documents, you must select which ones to vectorize. The documents will be split into chunks which are then stored and vectorized into the Milvus database. These chunks will be used to generate the RAG prompt when you query the LLM. The Query LLM page will provide an interface for asking questions to the LLM. There are additional settings here which lets you change the LLM that is being used (the IBM instructlab/granite-7b-lab model is the default). Each LLM will behave differently so it is often an interesting exercise to try the same questions with different models. You can set whether or not a RAG prompt is generated as part of your query, as well as adjust how many sentence chunks from the vector database will be used to construct the prompt. If you want to try a different LLM, you can use the Add LLM panel to load an LLM found in the Ollama or Hugging Face library. The load step will download the model to the local server and then make it available as an LLM that you can ask questions of. If you find that the system is not being responsive, you may want to check the Diagnostics page to see if the watsonx.data services are running. You can restart many of the services from this dialog. In addition, the Log file may provide more details on what went wrong. Finally, details about this system and the programs that were used to create this are listed in the Support section. Remember that this system does not contain GPUs which limits the performance of the LLM. However, it does provide an environment to try out RAG prompts and observe how different LLMs behave with and without RAG prompts.","title":"System Overview"},{"location":"wxd-demo-log/","text":"Log File The log file (/tmp/watsonx.log) contains information on what code was run during your session and any error messages that may have been generated. The log file contains details on what code was run within the demonstration system, and it will also contain more detailed error messages that you can use to diagnose any problems in the system. There is a copy to clipboard icon on the top right side of the text display that you can use to download the log file to your system. Use the Clear Log button to clear the contents of the log. The log display will not be refreshed until the next time you access this dialog.","title":"Log File"},{"location":"wxd-demo-log/#log-file","text":"The log file (/tmp/watsonx.log) contains information on what code was run during your session and any error messages that may have been generated. The log file contains details on what code was run within the demonstration system, and it will also contain more detailed error messages that you can use to diagnose any problems in the system. There is a copy to clipboard icon on the top right side of the text display that you can use to download the log file to your system. Use the Clear Log button to clear the contents of the log. The log display will not be refreshed until the next time you access this dialog.","title":"Log File"},{"location":"wxd-demo-managellm/","text":"Managing LLMs This system has been built using the IBM instructlab/granite-7b-lab model. You can load additional models into the system by using the Add LLM Dialog. The LLMs that are currently in the system are: Name Author Link gemma:2b Google https://ollama.com/library/gemma2 instructlab/granite-7b-lab IBM https://ollama.com/instructlab/granite-7b-lab instructlab/merlinite-7b-lab IBM https://ollama.com/instructlab/merlinite-7b-lab Ilama3 Meta https://ollama.com/library/llama3 llama3.2:lb-instruct-q8_0 Meta https://ollama.com/library/llama3.2 tinyllama:l.lb-chat-vl-q8_0 StatNLP Research Group https://ollama.com/library/tinyllama mistral-small Mistral AI https://ollama.com/library/mistral-small phi3:3.8b-mini-128k-instruct-q8_0 Microsoft https://ollama.com/library/phi3 Below the list of LLMs are options to add a new LLM or remove one from the system. Loading an LLM LLMs can be found at Ollama and Hugging Face . In order to load the LLM into the system, the LLM must be cataloged in the Ollama library. Doublecheck the licensing requirements of any LLM you choose to download. While most of the LLMs provide an open source license for testing and demonstrations, several of them do not allow for commercial use. The following screen shows the results of searching for IBM in the Ollama library. If we select the granite3-dense model, we are provided with more details on the model. You must decide which version of the LLM you want to use. The pulldown list on the far left side will provide various versions of the LLM to download. In this example, we will select the smaller 2Gb version. The full name of the LLM will be populated in box to the right of the model you selected. There is a copy button beside the name that you can use to copy the LLM name. Place your cursor into the LLM name field and use the paste key (Windows/Linux Ctrl + v , Mac Cmd + v ) to place the value into the field. The format of the LLM name is not correct as pasted. The front of the LLM name is prefixed with ollama run which needs to be removed. The field should only contain the name of the LLM model or granite3-dense:2b . Once you have updated the name, press the Load LLM button to begin the load process. Usually the load process takes a minute or so to complete since it is downloading gigabytes of data. When the load is done, a success or failure message will be displayed. You can check that the LLM has loaded by pressing the Refresh List button at the top of the screen. Removing an LLM If you find that an LLM is not suitable for your demonstrations, you can remove it from the system by selecting the name of the LLM from the pull-down list. If this is the LLM you want to remove, press the Delete LLM button to remove it from the system. The system will provide a success message once the deletion is complete.","title":"Manage LLM"},{"location":"wxd-demo-managellm/#managing-llms","text":"This system has been built using the IBM instructlab/granite-7b-lab model. You can load additional models into the system by using the Add LLM Dialog. The LLMs that are currently in the system are: Name Author Link gemma:2b Google https://ollama.com/library/gemma2 instructlab/granite-7b-lab IBM https://ollama.com/instructlab/granite-7b-lab instructlab/merlinite-7b-lab IBM https://ollama.com/instructlab/merlinite-7b-lab Ilama3 Meta https://ollama.com/library/llama3 llama3.2:lb-instruct-q8_0 Meta https://ollama.com/library/llama3.2 tinyllama:l.lb-chat-vl-q8_0 StatNLP Research Group https://ollama.com/library/tinyllama mistral-small Mistral AI https://ollama.com/library/mistral-small phi3:3.8b-mini-128k-instruct-q8_0 Microsoft https://ollama.com/library/phi3 Below the list of LLMs are options to add a new LLM or remove one from the system.","title":"Managing LLMs"},{"location":"wxd-demo-managellm/#loading-an-llm","text":"LLMs can be found at Ollama and Hugging Face . In order to load the LLM into the system, the LLM must be cataloged in the Ollama library. Doublecheck the licensing requirements of any LLM you choose to download. While most of the LLMs provide an open source license for testing and demonstrations, several of them do not allow for commercial use. The following screen shows the results of searching for IBM in the Ollama library. If we select the granite3-dense model, we are provided with more details on the model. You must decide which version of the LLM you want to use. The pulldown list on the far left side will provide various versions of the LLM to download. In this example, we will select the smaller 2Gb version. The full name of the LLM will be populated in box to the right of the model you selected. There is a copy button beside the name that you can use to copy the LLM name. Place your cursor into the LLM name field and use the paste key (Windows/Linux Ctrl + v , Mac Cmd + v ) to place the value into the field. The format of the LLM name is not correct as pasted. The front of the LLM name is prefixed with ollama run which needs to be removed. The field should only contain the name of the LLM model or granite3-dense:2b . Once you have updated the name, press the Load LLM button to begin the load process. Usually the load process takes a minute or so to complete since it is downloading gigabytes of data. When the load is done, a success or failure message will be displayed. You can check that the LLM has loaded by pressing the Refresh List button at the top of the screen.","title":"Loading an LLM"},{"location":"wxd-demo-managellm/#removing-an-llm","text":"If you find that an LLM is not suitable for your demonstrations, you can remove it from the system by selecting the name of the LLM from the pull-down list. If this is the LLM you want to remove, press the Delete LLM button to remove it from the system. The system will provide a success message once the deletion is complete.","title":"Removing an LLM"},{"location":"wxd-demo-menu/","text":"Main Menu Your TechZone reservation will contain two URLs that you will use to connect to the demonstration: The first URL (IBM watsonx.data and Milvus Demo) is the link that will connect you to the demonstration system. The second link (watsonx.data UI) provides access to the watsonx.data UI where you can explore the contents of the watsonx.data environment. There is a section in the Appendix ( watsonxui ) which provides details on how to navigate watsonx.data using the UI. Log In To access the watsonx.data and Milvus demo, click on the link in your reservation. Note that the server name and port number will be different in your environment. IBM watsonx.data and Milvus Demonstration: https://na4.services.cloud.techzone.ibm.com:xxxxx An initial login panel will be displayed: Enter the userid and password below to access the system. Enter the credentials for the watsonx user and press Log in Username: watsonx Password: watsonx.data Subsequent Log In If you stop using the system for a period of time, the Log In screen will re-appear. You may also see an error message displayed that suggests some components are not available. This error is due to the system restarting but several of the parallel processes not being initialized. If this is the case, use the browser refresh button to restart the process and the error message will disappear. Initialization Once you have log into the demo system, it will begin updating the software with the latest version of the application, along with refreshing any demo documents being used in the system. The system will provide a progress indicator: Checking Milvus Checking Presto Removing old collections Insert default documents Updating LLM Engine (not shown) Once the updates are complete, the main menu will be displayed. Main Menu The main menu consists of a navigation bar on the left side of the display, and several tiles which provide details and links to the different parts of the application. The scroll bar is on the far right side of the display. Scrolling down will reveal the remainder of the options available in the demonstration. The menus are divided into three sections: System Overview Details on what components make up the system and links to documentation. Document Storage, Vectorization, and LLM Queries The main section of the application revolves around document (URL) storage, vectorizing these documents, and then using an LLM with RAG to answer questions. LLM Maintenance, Diagnostics and Support If you need to diagnose problems in the system, this section provides several ways of correcting or restarting services. You can also manage which LLM models you use in the environment. System Overview The System Overview provides links to documentation and details on how the system has been created. Introduction This section provides details of what the system is demonstrating. It provides a condensed version of the details that are found in this documentation. Retrieval Augmented Generation If you are not familiar with the concept of RAG, this panel will provide some details on how it is used with LLMs. Documentation Support This link will display the documentation which you are currently reading. Document Storage, Vectorization, and LLM Queries The Document Storage, Vectorization, and LLM Queries section is the one where you will spend most of your time in the demonstration. Import Documents In order to generate RAG prompts, the system must have documents that it can extract sentences from. The system provides an interface that allows you to load documents from your local machine, URLs from a website, or documents that are selected from Wikipedia. A default document (IBM 2023 earnings summary) is provided for you to test with. These documents are registered and stored within the watsonx.data environment. Vectorize Documents In order to use RAG prompts, documents need to be vectorized into the Milvus database. Based on the question being asked, a RAG prompt will be generated from the sentence vectors that are found in the Milvus database. Query LLM Once at least one document collection has been created, you can ask an LLM a question and use RAG generation to provide more details to the LLM. You can select which document collection to use, the setting to use for generating the RAG prompt, and which LLM to use to answer the question. LLM Maintenance, Diagnostics and Support The LLM Maintenance, Diagnostics and Support section provides help for situations where the system is not working. Manage LLMs Several LLMs (instructlab/granite-7b-lab) are provided in the system. You can add a new LLM to the system or remove ones that you are not using. Diagnostics The diagnostics panel provides several options for checking the operation of the system. You can restart many of the services and reset the database from scratch if you believe that it has been corrupted. Log File The program will log many of the operations that are performed by the system. If you come across an error during use of the system, the log file many provide some guidance on what went wrong. Support Links to the various components used in the system are provided in this panel. Home Button On several of the screens you will see a Home button at the bottom of the screen. Pressing the Home button will return you to the main menu.","title":"Main Menu"},{"location":"wxd-demo-menu/#main-menu","text":"Your TechZone reservation will contain two URLs that you will use to connect to the demonstration: The first URL (IBM watsonx.data and Milvus Demo) is the link that will connect you to the demonstration system. The second link (watsonx.data UI) provides access to the watsonx.data UI where you can explore the contents of the watsonx.data environment. There is a section in the Appendix ( watsonxui ) which provides details on how to navigate watsonx.data using the UI.","title":"Main Menu"},{"location":"wxd-demo-menu/#log-in","text":"To access the watsonx.data and Milvus demo, click on the link in your reservation. Note that the server name and port number will be different in your environment. IBM watsonx.data and Milvus Demonstration: https://na4.services.cloud.techzone.ibm.com:xxxxx An initial login panel will be displayed: Enter the userid and password below to access the system. Enter the credentials for the watsonx user and press Log in Username: watsonx Password: watsonx.data","title":"Log In"},{"location":"wxd-demo-menu/#subsequent-log-in","text":"If you stop using the system for a period of time, the Log In screen will re-appear. You may also see an error message displayed that suggests some components are not available. This error is due to the system restarting but several of the parallel processes not being initialized. If this is the case, use the browser refresh button to restart the process and the error message will disappear.","title":"Subsequent Log In"},{"location":"wxd-demo-menu/#initialization","text":"Once you have log into the demo system, it will begin updating the software with the latest version of the application, along with refreshing any demo documents being used in the system. The system will provide a progress indicator: Checking Milvus Checking Presto Removing old collections Insert default documents Updating LLM Engine (not shown) Once the updates are complete, the main menu will be displayed.","title":"Initialization"},{"location":"wxd-demo-menu/#main-menu_1","text":"The main menu consists of a navigation bar on the left side of the display, and several tiles which provide details and links to the different parts of the application. The scroll bar is on the far right side of the display. Scrolling down will reveal the remainder of the options available in the demonstration. The menus are divided into three sections: System Overview Details on what components make up the system and links to documentation. Document Storage, Vectorization, and LLM Queries The main section of the application revolves around document (URL) storage, vectorizing these documents, and then using an LLM with RAG to answer questions. LLM Maintenance, Diagnostics and Support If you need to diagnose problems in the system, this section provides several ways of correcting or restarting services. You can also manage which LLM models you use in the environment.","title":"Main Menu"},{"location":"wxd-demo-menu/#system-overview","text":"The System Overview provides links to documentation and details on how the system has been created. Introduction This section provides details of what the system is demonstrating. It provides a condensed version of the details that are found in this documentation. Retrieval Augmented Generation If you are not familiar with the concept of RAG, this panel will provide some details on how it is used with LLMs. Documentation Support This link will display the documentation which you are currently reading.","title":"System Overview"},{"location":"wxd-demo-menu/#document-storage-vectorization-and-llm-queries","text":"The Document Storage, Vectorization, and LLM Queries section is the one where you will spend most of your time in the demonstration. Import Documents In order to generate RAG prompts, the system must have documents that it can extract sentences from. The system provides an interface that allows you to load documents from your local machine, URLs from a website, or documents that are selected from Wikipedia. A default document (IBM 2023 earnings summary) is provided for you to test with. These documents are registered and stored within the watsonx.data environment. Vectorize Documents In order to use RAG prompts, documents need to be vectorized into the Milvus database. Based on the question being asked, a RAG prompt will be generated from the sentence vectors that are found in the Milvus database. Query LLM Once at least one document collection has been created, you can ask an LLM a question and use RAG generation to provide more details to the LLM. You can select which document collection to use, the setting to use for generating the RAG prompt, and which LLM to use to answer the question.","title":"Document Storage, Vectorization, and LLM Queries"},{"location":"wxd-demo-menu/#llm-maintenance-diagnostics-and-support","text":"The LLM Maintenance, Diagnostics and Support section provides help for situations where the system is not working. Manage LLMs Several LLMs (instructlab/granite-7b-lab) are provided in the system. You can add a new LLM to the system or remove ones that you are not using. Diagnostics The diagnostics panel provides several options for checking the operation of the system. You can restart many of the services and reset the database from scratch if you believe that it has been corrupted. Log File The program will log many of the operations that are performed by the system. If you come across an error during use of the system, the log file many provide some guidance on what went wrong. Support Links to the various components used in the system are provided in this panel.","title":"LLM Maintenance, Diagnostics and Support"},{"location":"wxd-demo-menu/#home-button","text":"On several of the screens you will see a Home button at the bottom of the screen. Pressing the Home button will return you to the main menu.","title":"Home Button"},{"location":"wxd-demo-queryllm/","text":"Query LLM The Query LLM panel is used to ask questions of the LLM. The central part of the screen contains the chat window. The question that you want to ask the LLM is placed into the text box at the bottom of the screen, press Enter , and the response will be placed into the chat window underneath your question. System performance is limited by the lack of GPUs Note that this system does not have GPUs attached to it so the response may take a minute or so to return. The initial question will load the LLM into memory which will result in a delay in answering the question. Subsequent questions will usually be answered faster. When you switch LLMs, the new LLM will need to be loaded into memory. Take this into account when you are demoing different LLMs. The left side of the screen contains options that will change the behavior of the LLM. These options are discussed in the sections below. LLM Options Current LLM Model The LLM table provides a list of LLMs that are currently loaded into the system. Choose which LLM you want to use to answer your query. The default LLM is the Instructlab/granite-7b-lab model. If you want to add more LLMs to the system, use the Add LLM model dialog. Use the Clear conversation button to clear the history of questions and LLM responses. If you find that the LLM is taking too long to respond (or saying too much), press the Stop LLM Response button. Note that stopping the LLM will clear the last response on the screen. Current Document Collections The list of collections that have been vectorized are found in this table. Select which collection you want to use when generating the RAG prompt. Make sure that you are using a document collection that matches the question you are asking the LLM! Prompt Settings The Prompt Settings determine how the RAG prompt gets generated when querying the LLM. Use RAG Prompt The Use RAG prompt option will tell the program to generate a RAG response. If this is turned off, the question is sent \"as is\" to the LLM. This provides an opportunity to see what the LLM answer will be without a RAG prompt. Turning on the RAG prompt and then asking the same question will demonstrate how the RAG prompt can help the LLM generate a better answer. Display RAG Prompt The Display RAG prompt option will include the complete RAG prompt on the screen. If you want to hide the RAG prompt, turn the Display RAG prompt off. Concise Response The Concise response option will tell the LLM to limit the answer to your question. If you turn Concise output off, the LLM will be allowed to answer your question without length restrictions. The trade-off when turning off the concise option is the amount of time it takes to return the full output from the LLM. Random Seed The Random Seed option will use a random number to \"seed\" the LLM. When a random number is used, the answer to a question will vary. When using a fixed seed, the answer to a question should remain the same. Display Settings The Display Settings option will provide a summary of the settings used underneath the question. This provides a history of what parameters were used when asking a question to the LLM. Maximum RAG Sentences The Minimum RAG Sentences slider is used to limit the number of sentences that the RAG program will use in the question. The default number of sentences is 3. Using a larger number of sentences will slow down the LLM response, but it may result in a higher quality answer. Temperature The Temperature slider generates a value between 0 and 2 with 0.7 being the default. Use a lower temperature value when you want more dependable output. Use a higher temperature value when you want to increase the randomness and variability or the output, such as when you want creative output. Remember, randomness can also lead to inaccurate or nonsensical output. Questions The left sidebar includes a list of questions previously sent to the LLM. To copy a question into the LLM prompt, use the following steps: Click on the question you want to copy from the list (it will be highlighted) Use the keyboard copy button (Windows/Linux Ctrl + c , Mac Cmd + c ) to place the value onto the clipboard Click on the LLM question input line Use keyboard paste button (Windows/Linux Ctrl + v , Mac Cmd + v ) to place the copied value into the line Technical Details The process which takes place when you enter a question is: The question is turned into a vector value The value is compared to the sentence vectors that were generated in the Vectorize Document step (Document collection) The 3 best sentences (or whatever you may have set the sentence limit to) will be used to generate a RAG prompt The RAG prompt is sent to the LLM The program displays the results as they are generated by the LLM If you want to view the Milvus vector distance for the RAG prompts, view the LOG file output.","title":"Query LLM"},{"location":"wxd-demo-queryllm/#query-llm","text":"The Query LLM panel is used to ask questions of the LLM. The central part of the screen contains the chat window. The question that you want to ask the LLM is placed into the text box at the bottom of the screen, press Enter , and the response will be placed into the chat window underneath your question. System performance is limited by the lack of GPUs Note that this system does not have GPUs attached to it so the response may take a minute or so to return. The initial question will load the LLM into memory which will result in a delay in answering the question. Subsequent questions will usually be answered faster. When you switch LLMs, the new LLM will need to be loaded into memory. Take this into account when you are demoing different LLMs. The left side of the screen contains options that will change the behavior of the LLM. These options are discussed in the sections below.","title":"Query LLM"},{"location":"wxd-demo-queryllm/#llm-options","text":"","title":"LLM Options"},{"location":"wxd-demo-queryllm/#current-llm-model","text":"The LLM table provides a list of LLMs that are currently loaded into the system. Choose which LLM you want to use to answer your query. The default LLM is the Instructlab/granite-7b-lab model. If you want to add more LLMs to the system, use the Add LLM model dialog. Use the Clear conversation button to clear the history of questions and LLM responses. If you find that the LLM is taking too long to respond (or saying too much), press the Stop LLM Response button. Note that stopping the LLM will clear the last response on the screen.","title":"Current LLM Model"},{"location":"wxd-demo-queryllm/#current-document-collections","text":"The list of collections that have been vectorized are found in this table. Select which collection you want to use when generating the RAG prompt. Make sure that you are using a document collection that matches the question you are asking the LLM!","title":"Current Document Collections"},{"location":"wxd-demo-queryllm/#prompt-settings","text":"The Prompt Settings determine how the RAG prompt gets generated when querying the LLM.","title":"Prompt Settings"},{"location":"wxd-demo-queryllm/#use-rag-prompt","text":"The Use RAG prompt option will tell the program to generate a RAG response. If this is turned off, the question is sent \"as is\" to the LLM. This provides an opportunity to see what the LLM answer will be without a RAG prompt. Turning on the RAG prompt and then asking the same question will demonstrate how the RAG prompt can help the LLM generate a better answer.","title":"Use RAG Prompt"},{"location":"wxd-demo-queryllm/#display-rag-prompt","text":"The Display RAG prompt option will include the complete RAG prompt on the screen. If you want to hide the RAG prompt, turn the Display RAG prompt off.","title":"Display RAG Prompt"},{"location":"wxd-demo-queryllm/#concise-response","text":"The Concise response option will tell the LLM to limit the answer to your question. If you turn Concise output off, the LLM will be allowed to answer your question without length restrictions. The trade-off when turning off the concise option is the amount of time it takes to return the full output from the LLM.","title":"Concise Response"},{"location":"wxd-demo-queryllm/#random-seed","text":"The Random Seed option will use a random number to \"seed\" the LLM. When a random number is used, the answer to a question will vary. When using a fixed seed, the answer to a question should remain the same.","title":"Random Seed"},{"location":"wxd-demo-queryllm/#display-settings","text":"The Display Settings option will provide a summary of the settings used underneath the question. This provides a history of what parameters were used when asking a question to the LLM.","title":"Display Settings"},{"location":"wxd-demo-queryllm/#maximum-rag-sentences","text":"The Minimum RAG Sentences slider is used to limit the number of sentences that the RAG program will use in the question. The default number of sentences is 3. Using a larger number of sentences will slow down the LLM response, but it may result in a higher quality answer.","title":"Maximum RAG Sentences"},{"location":"wxd-demo-queryllm/#temperature","text":"The Temperature slider generates a value between 0 and 2 with 0.7 being the default. Use a lower temperature value when you want more dependable output. Use a higher temperature value when you want to increase the randomness and variability or the output, such as when you want creative output. Remember, randomness can also lead to inaccurate or nonsensical output.","title":"Temperature"},{"location":"wxd-demo-queryllm/#questions","text":"The left sidebar includes a list of questions previously sent to the LLM. To copy a question into the LLM prompt, use the following steps: Click on the question you want to copy from the list (it will be highlighted) Use the keyboard copy button (Windows/Linux Ctrl + c , Mac Cmd + c ) to place the value onto the clipboard Click on the LLM question input line Use keyboard paste button (Windows/Linux Ctrl + v , Mac Cmd + v ) to place the copied value into the line","title":"Questions"},{"location":"wxd-demo-queryllm/#technical-details","text":"The process which takes place when you enter a question is: The question is turned into a vector value The value is compared to the sentence vectors that were generated in the Vectorize Document step (Document collection) The 3 best sentences (or whatever you may have set the sentence limit to) will be used to generate a RAG prompt The RAG prompt is sent to the LLM The program displays the results as they are generated by the LLM If you want to view the Milvus vector distance for the RAG prompts, view the LOG file output.","title":"Technical Details"},{"location":"wxd-demo-rag/","text":"Retrieval Augmented Generation RAG is an AI framework for retrieving facts from an external knowledge base to ground large language models (LLMs) on the most accurate, up-to-date information and to give users insight into LLMs' generative process. Large language models can be inconsistent. Sometimes they nail the answer to questions, other times they regurgitate random facts from their training data. If they occasionally sound like they have no idea what they're saying, it's because they don't. LLMs know how words relate statistically, but not what they mean. Retrieval-augmented generation (RAG) is an AI framework for improving the quality of LLM-generated responses by grounding the model on external sources of knowledge to supplement the LLM's internal representation of information. Implementing RAG in an LLM-based question answering system has two main benefits: It ensures that the model has access to the most current, reliable facts, and that users have access to the model's sources, ensuring that its claims can be checked for accuracy and ultimately trusted. RAG has additional benefits. By grounding an LLM on a set of external, verifiable facts, the model has fewer opportunities to pull information baked into its parameters. This reduces the chances that an LLM will leak sensitive data, or 'hallucinate' incorrect or misleading information. RAG also reduces the need for users to continuously train the model on new data and update its parameters as circumstances evolve. In this way, RAG can lower the computational and financial costs of running LLM-powered chatbots in an enterprise setting. IBM unveiled its new AI and data platform, watsonx, which offers RAG, back in May. Credit: Kim Martineau URL: What is retrieval-augmented generation? This system is designed to use information found in documents and URLs to generate a RAG prompt to an LLM. You can experiment with using different documents, RAG settings, and LLMs to discover how the answers to your questions can change.","title":"RAG"},{"location":"wxd-demo-rag/#retrieval-augmented-generation","text":"RAG is an AI framework for retrieving facts from an external knowledge base to ground large language models (LLMs) on the most accurate, up-to-date information and to give users insight into LLMs' generative process. Large language models can be inconsistent. Sometimes they nail the answer to questions, other times they regurgitate random facts from their training data. If they occasionally sound like they have no idea what they're saying, it's because they don't. LLMs know how words relate statistically, but not what they mean. Retrieval-augmented generation (RAG) is an AI framework for improving the quality of LLM-generated responses by grounding the model on external sources of knowledge to supplement the LLM's internal representation of information. Implementing RAG in an LLM-based question answering system has two main benefits: It ensures that the model has access to the most current, reliable facts, and that users have access to the model's sources, ensuring that its claims can be checked for accuracy and ultimately trusted. RAG has additional benefits. By grounding an LLM on a set of external, verifiable facts, the model has fewer opportunities to pull information baked into its parameters. This reduces the chances that an LLM will leak sensitive data, or 'hallucinate' incorrect or misleading information. RAG also reduces the need for users to continuously train the model on new data and update its parameters as circumstances evolve. In this way, RAG can lower the computational and financial costs of running LLM-powered chatbots in an enterprise setting. IBM unveiled its new AI and data platform, watsonx, which offers RAG, back in May. Credit: Kim Martineau URL: What is retrieval-augmented generation? This system is designed to use information found in documents and URLs to generate a RAG prompt to an LLM. You can experiment with using different documents, RAG settings, and LLMs to discover how the answers to your questions can change.","title":"Retrieval Augmented Generation"},{"location":"wxd-demo-support/","text":"Support Development George Baklarz, Americas Data and AI Technical Sales email: baklarz@ca.ibm.com Slack Channel: #watsonx-data-rag-demo Testing and Design Feedback Dale McInnis, Americas Data and AI Technical Sales Concept Based on work by Elena M\u00e1rquez and Srajan Dube Milvus Vector Encoding Based on work by Katherine Ciaravalli TechZone Support Special Thanks to Ben Foulkes for supporting this effort in TechZone Server Techzone VMWare environment Red Hat Linux 9 16 VPC, 64 Gb Server System Software Watsonx.data 2.0.2 - IBM Data Lakehouse environment Presto 0.286 - Database engine used to query data in the lakehouse Milvus - Vector database included in watsonx.data Ollama - Platform for running LLMs locally Application Libraries Streamlit - Web interface framework Llama Index - Data framework for building LLM applications pyMilvus - Python SDK of Milvus prestodb - Presto client langchain - LangChain is a framework designed to simplify LLM applications sqlalchemy - SQLAlchemy is an Object Relational Mapper for database interactions sentence_transformer - Sentence Transformers provides modules for accessing, using, and training embedded models pandas - pandas provides data structures designed to work with relational or tabular data","title":"Support"},{"location":"wxd-demo-support/#support","text":"Development George Baklarz, Americas Data and AI Technical Sales email: baklarz@ca.ibm.com Slack Channel: #watsonx-data-rag-demo Testing and Design Feedback Dale McInnis, Americas Data and AI Technical Sales Concept Based on work by Elena M\u00e1rquez and Srajan Dube Milvus Vector Encoding Based on work by Katherine Ciaravalli TechZone Support Special Thanks to Ben Foulkes for supporting this effort in TechZone Server Techzone VMWare environment Red Hat Linux 9 16 VPC, 64 Gb Server System Software Watsonx.data 2.0.2 - IBM Data Lakehouse environment Presto 0.286 - Database engine used to query data in the lakehouse Milvus - Vector database included in watsonx.data Ollama - Platform for running LLMs locally Application Libraries Streamlit - Web interface framework Llama Index - Data framework for building LLM applications pyMilvus - Python SDK of Milvus prestodb - Presto client langchain - LangChain is a framework designed to simplify LLM applications sqlalchemy - SQLAlchemy is an Object Relational Mapper for database interactions sentence_transformer - Sentence Transformers provides modules for accessing, using, and training embedded models pandas - pandas provides data structures designed to work with relational or tabular data","title":"Support"},{"location":"wxd-demo-vectorize/","text":"Vectorize Documents Milvus is a vector database that stores, indexes, and manages massive embedding vectors that are developed by deep neural networks and other machine learning (ML) models. It is developed to empower embedding similarity search and AI applications. Milvus makes unstructured data search more accessible and consistent across various environments. The watsonx.data system that you are running includes the Milvus server. The Milvus vector database is used to store sentences extracted from documents, and then convert them into vectors for searching. Vectorize Documents The Vectorize panel displays the list of document collections, the documents stored in the watsonx.data system, and an option to vectorize one or more documents. Current Document Collections A document collection is made up of a series of documents that have been vectorized. In the screen above, only one collection (IBM_2023_Annual_Report) is currently loaded into the system. If you decide to generate a RAG prompt when querying an LLM, you must specify this document collection. A document collection is made up of a one or more documents (or URLs) that are transformed into vectors and stored in Milvus. When querying an LLM, the Milvus vector database will search the document collection for sentences to use as part of the RAG generation. Document Collections You can include as many documents, URLs, or Wiki documents in your document collection. The documents will be combined and stored as vectors in the Milvus database. The only criteria for your documents is that the topics covered by your documents are the same. Document List The document list contains all the documents and URLs that have been registered in the system. One or more documents make up a collection. Select the documents that you want to be included in a collection, and they will be vectorized as a group in Milvus. Provide a unique name for your collection and then press the Vectorize Collection button. If you use the name of an existing collection, the contents of that collection will be overwritten with the new documents. Once you press the Vectorize Collection button, the documents will be converted into vectors and stored in Milvus. This process may take a few minutes to complete depending on the size of the documents. The collection will now be available for your RAG generation step. If you receive an error message during the vectorize step, you may need to load a conversion library in order for the text to be extracted from the document. In this example, we tried to vectorize a Microsoft Word file with an extension of .DOCX . Details on how to fix this error can be found in the Diagnostics section. Technical Details In order to create a RAG (Retrieval Augmented Generation), one or more documents must be selected from the database, the text extracted, and then stored into Milvus and vectorized. The process to vectorize a document involves converting the document (PPT, PDF, etc...) into RAW text. Once the text is available, the text is split into smaller chunks, with each chunk containing 512 or so tokens. A token is loosely compared to a word. These chunks are stored in the Milvus database and the text is vectorized using an algorithm (sentence-transformers/all-MiniLM-L6-v2). Once the vectorization is completed, we can search the data for similar sentences when generating a RAG prompt. The LLM can run without using a document collection, but it will not be able to generate a RAG prompt.","title":"Vectorize Documents"},{"location":"wxd-demo-vectorize/#vectorize-documents","text":"Milvus is a vector database that stores, indexes, and manages massive embedding vectors that are developed by deep neural networks and other machine learning (ML) models. It is developed to empower embedding similarity search and AI applications. Milvus makes unstructured data search more accessible and consistent across various environments. The watsonx.data system that you are running includes the Milvus server. The Milvus vector database is used to store sentences extracted from documents, and then convert them into vectors for searching.","title":"Vectorize Documents"},{"location":"wxd-demo-vectorize/#vectorize-documents_1","text":"The Vectorize panel displays the list of document collections, the documents stored in the watsonx.data system, and an option to vectorize one or more documents.","title":"Vectorize Documents"},{"location":"wxd-demo-vectorize/#current-document-collections","text":"A document collection is made up of a series of documents that have been vectorized. In the screen above, only one collection (IBM_2023_Annual_Report) is currently loaded into the system. If you decide to generate a RAG prompt when querying an LLM, you must specify this document collection. A document collection is made up of a one or more documents (or URLs) that are transformed into vectors and stored in Milvus. When querying an LLM, the Milvus vector database will search the document collection for sentences to use as part of the RAG generation. Document Collections You can include as many documents, URLs, or Wiki documents in your document collection. The documents will be combined and stored as vectors in the Milvus database. The only criteria for your documents is that the topics covered by your documents are the same.","title":"Current Document Collections"},{"location":"wxd-demo-vectorize/#document-list","text":"The document list contains all the documents and URLs that have been registered in the system. One or more documents make up a collection. Select the documents that you want to be included in a collection, and they will be vectorized as a group in Milvus. Provide a unique name for your collection and then press the Vectorize Collection button. If you use the name of an existing collection, the contents of that collection will be overwritten with the new documents. Once you press the Vectorize Collection button, the documents will be converted into vectors and stored in Milvus. This process may take a few minutes to complete depending on the size of the documents. The collection will now be available for your RAG generation step. If you receive an error message during the vectorize step, you may need to load a conversion library in order for the text to be extracted from the document. In this example, we tried to vectorize a Microsoft Word file with an extension of .DOCX . Details on how to fix this error can be found in the Diagnostics section.","title":"Document List"},{"location":"wxd-demo-vectorize/#technical-details","text":"In order to create a RAG (Retrieval Augmented Generation), one or more documents must be selected from the database, the text extracted, and then stored into Milvus and vectorized. The process to vectorize a document involves converting the document (PPT, PDF, etc...) into RAW text. Once the text is available, the text is split into smaller chunks, with each chunk containing 512 or so tokens. A token is loosely compared to a word. These chunks are stored in the Milvus database and the text is vectorized using an algorithm (sentence-transformers/all-MiniLM-L6-v2). Once the vectorization is completed, we can search the data for similar sentences when generating a RAG prompt. The LLM can run without using a document collection, but it will not be able to generate a RAG prompt.","title":"Technical Details"},{"location":"wxd-disclaimer/","text":"Disclaimer IBM watsonx.data Copyright \u00a9 2024 by International Business Machines Corporation (IBM). All rights reserved. Printed in Canada. Except as permitted under the Copyright Act of 1976, no part of this publication may be reproduced or distributed in any form or by any means, or stored in a database or retrieval system, without the prior written permission of IBM, with the exception that the program listings may be entered, stored, and executed in a computer system, but they may not be reproduced for publication. The contents of this lab represent those features that may or may not be available in the current release of any products mentioned within this lab despite what the lab may say. IBM reserves the right to include or exclude any functionality mentioned in this lab for the current release of watsonx.data, or a subsequent release. In addition, any claims made in this lab are not official communications by IBM; rather, they are observed by the authors in unaudited testing and research. The views expressed in this lab is those of the authors and not necessarily those of the IBM Corporation; both are not liable for any of the claims, assertions, or contents in this lab. IBM's statements regarding its plans, directions, and intent are subject to change or withdrawal without notice and at IBM's sole discretion. Information regarding potential future products is intended to outline our general product direction and it should not be relied on in making a purchasing decision. The information mentioned regarding potential future products is not a commitment, promise, or legal obligation to deliver any material, code, or functionality. Information about potential future products may not be incorporated into any contract. The development, release, and timing of any future feature or functionality described for our products remains at our sole discretion. Performance is based on measurements and projections using standard IBM benchmarks in a controlled environment. The actual throughput or performance that any user will experience will vary depending upon many factors, including considerations such as the amount of multiprogramming in the user's job stream, the I/O configuration, the storage configuration, and the workload processed. Therefore, no assurance can be given that an individual user will achieve results like those stated here. U.S. Government Users Restricted Rights - Use, duplication or disclosure restricted by GSA ADP Schedule Contract with IBM. Information in this eBook (including information relating to products that have not yet been announced by IBM) has been reviewed for accuracy as of the date of initial publication and could include unintentional technical or typographical errors. IBM shall have no responsibility to update this information. THIS DOCUMENT IS DISTRIBUTED \"AS IS\" WITHOUT ANY WARRANTY, EITHER EXPRESS OR IMPLIED. IN NO EVENT SHALL IBM BE LIABLE FOR ANY DAMAGE ARISING FROM THE USE OF THIS INFORMATION, INCLUDING BUT NOT LIMITED TO, LOSS OF DATA, BUSINESS INTERRUPTION, LOSS OF PROFIT OR LOSS OF OPPORTUNITY. IBM products and services are warranted according to the terms and conditions of the agreements under which they are provided. References in this document to IBM products, programs, or services does not imply that IBM intends to make such products, programs, or services available in all countries in which IBM operates or does business. Information concerning non-IBM products was obtained from the suppliers of those products, their published announcements, or other publicly available sources. IBM has not tested those products in connection with this publication and cannot confirm the accuracy of performance, compatibility or any other claims related to non-IBM products. Questions on the capabilities of non-IBM products should be addressed to the suppliers of those products. IBM does not warrant the quality of any third-party products, or the ability of any such third-party products to interoperate with IBM's products. IBM EXPRESSLY DISCLAIMS ALL WARRANTIES, EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. The provision of the information contained herein is not intended to, and does not, grant any right or license under any IBM patents, copyrights, trademarks, or other intellectual property right. IBM, the IBM logo, ibm.com, Aspera\u00ae, Bluemix, Blueworks Live, CICS, Clearcase, Cognos\u00ae, DOORS\u00ae, Emptoris\u00ae, Enterprise Document Management System\u2122, FASP\u00ae, FileNet\u00ae, Global Business Services \u00ae, Global Technology Services \u00ae, IBM ExperienceOne\u2122, IBM SmartCloud\u00ae, IBM Social Business\u00ae, Information on Demand, ILOG, Maximo\u00ae, MQIntegrator\u00ae, MQSeries\u00ae, Netcool\u00ae, OMEGAMON, OpenPower, PureAnalytics\u2122, PureApplication\u00ae, pureCluster\u2122, PureCoverage\u00ae, PureData\u00ae, PureExperience\u00ae, PureFlex\u00ae, pureQuery\u00ae, pureScale\u00ae, PureSystems\u00ae, QRadar\u00ae, Rational\u00ae, Rhapsody\u00ae, Smarter Commerce\u00ae, SoDA, SPSS, Sterling Commerce\u00ae, StoredIQ, Tealeaf\u00ae, Tivoli\u00ae, Trusteer\u00ae, Unica\u00ae, urban{code}\u00ae, Watson, WebSphere\u00ae, Worklight\u00ae, X-Force\u00ae and System z\u00ae Z/OS, are trademarks of International Business Machines Corporation, registered in many jurisdictions worldwide. Other product and service names might be trademarks of IBM or other companies. A current list of IBM trademarks is available on the Web at \"Copyright and trademark information\" at: www.ibm.com/legal/copytrade.shtml. All trademarks or copyrights mentioned herein are the possession of their respective owners and IBM makes no claim of ownership by the mention of products that contain these marks.","title":"Disclaimer"},{"location":"wxd-disclaimer/#disclaimer","text":"","title":"Disclaimer"},{"location":"wxd-disclaimer/#ibm-watsonxdata","text":"Copyright \u00a9 2024 by International Business Machines Corporation (IBM). All rights reserved. Printed in Canada. Except as permitted under the Copyright Act of 1976, no part of this publication may be reproduced or distributed in any form or by any means, or stored in a database or retrieval system, without the prior written permission of IBM, with the exception that the program listings may be entered, stored, and executed in a computer system, but they may not be reproduced for publication. The contents of this lab represent those features that may or may not be available in the current release of any products mentioned within this lab despite what the lab may say. IBM reserves the right to include or exclude any functionality mentioned in this lab for the current release of watsonx.data, or a subsequent release. In addition, any claims made in this lab are not official communications by IBM; rather, they are observed by the authors in unaudited testing and research. The views expressed in this lab is those of the authors and not necessarily those of the IBM Corporation; both are not liable for any of the claims, assertions, or contents in this lab. IBM's statements regarding its plans, directions, and intent are subject to change or withdrawal without notice and at IBM's sole discretion. Information regarding potential future products is intended to outline our general product direction and it should not be relied on in making a purchasing decision. The information mentioned regarding potential future products is not a commitment, promise, or legal obligation to deliver any material, code, or functionality. Information about potential future products may not be incorporated into any contract. The development, release, and timing of any future feature or functionality described for our products remains at our sole discretion. Performance is based on measurements and projections using standard IBM benchmarks in a controlled environment. The actual throughput or performance that any user will experience will vary depending upon many factors, including considerations such as the amount of multiprogramming in the user's job stream, the I/O configuration, the storage configuration, and the workload processed. Therefore, no assurance can be given that an individual user will achieve results like those stated here. U.S. Government Users Restricted Rights - Use, duplication or disclosure restricted by GSA ADP Schedule Contract with IBM. Information in this eBook (including information relating to products that have not yet been announced by IBM) has been reviewed for accuracy as of the date of initial publication and could include unintentional technical or typographical errors. IBM shall have no responsibility to update this information. THIS DOCUMENT IS DISTRIBUTED \"AS IS\" WITHOUT ANY WARRANTY, EITHER EXPRESS OR IMPLIED. IN NO EVENT SHALL IBM BE LIABLE FOR ANY DAMAGE ARISING FROM THE USE OF THIS INFORMATION, INCLUDING BUT NOT LIMITED TO, LOSS OF DATA, BUSINESS INTERRUPTION, LOSS OF PROFIT OR LOSS OF OPPORTUNITY. IBM products and services are warranted according to the terms and conditions of the agreements under which they are provided. References in this document to IBM products, programs, or services does not imply that IBM intends to make such products, programs, or services available in all countries in which IBM operates or does business. Information concerning non-IBM products was obtained from the suppliers of those products, their published announcements, or other publicly available sources. IBM has not tested those products in connection with this publication and cannot confirm the accuracy of performance, compatibility or any other claims related to non-IBM products. Questions on the capabilities of non-IBM products should be addressed to the suppliers of those products. IBM does not warrant the quality of any third-party products, or the ability of any such third-party products to interoperate with IBM's products. IBM EXPRESSLY DISCLAIMS ALL WARRANTIES, EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. The provision of the information contained herein is not intended to, and does not, grant any right or license under any IBM patents, copyrights, trademarks, or other intellectual property right. IBM, the IBM logo, ibm.com, Aspera\u00ae, Bluemix, Blueworks Live, CICS, Clearcase, Cognos\u00ae, DOORS\u00ae, Emptoris\u00ae, Enterprise Document Management System\u2122, FASP\u00ae, FileNet\u00ae, Global Business Services \u00ae, Global Technology Services \u00ae, IBM ExperienceOne\u2122, IBM SmartCloud\u00ae, IBM Social Business\u00ae, Information on Demand, ILOG, Maximo\u00ae, MQIntegrator\u00ae, MQSeries\u00ae, Netcool\u00ae, OMEGAMON, OpenPower, PureAnalytics\u2122, PureApplication\u00ae, pureCluster\u2122, PureCoverage\u00ae, PureData\u00ae, PureExperience\u00ae, PureFlex\u00ae, pureQuery\u00ae, pureScale\u00ae, PureSystems\u00ae, QRadar\u00ae, Rational\u00ae, Rhapsody\u00ae, Smarter Commerce\u00ae, SoDA, SPSS, Sterling Commerce\u00ae, StoredIQ, Tealeaf\u00ae, Tivoli\u00ae, Trusteer\u00ae, Unica\u00ae, urban{code}\u00ae, Watson, WebSphere\u00ae, Worklight\u00ae, X-Force\u00ae and System z\u00ae Z/OS, are trademarks of International Business Machines Corporation, registered in many jurisdictions worldwide. Other product and service names might be trademarks of IBM or other companies. A current list of IBM trademarks is available on the Web at \"Copyright and trademark information\" at: www.ibm.com/legal/copytrade.shtml. All trademarks or copyrights mentioned herein are the possession of their respective owners and IBM makes no claim of ownership by the mention of products that contain these marks.","title":"IBM watsonx.data"},{"location":"wxd-intro-datamanager/","text":"Data Manager The Data manager page can be used to explore and curate your data. It includes a data objects navigation pane on the left side of the page with a navigable hierarchy of engine \u2192 catalog \u2192 schema \u2192 table. Click on the Data Manager icon on the left side of the screen When the Data manager initially starts, you may not see any values on the right-hand side of the screen. This side of the screen is populated when you expand one of the selections on the left side. Watsonx.data (Presto) organizes tables, views, and other database objects in schemas. A schema is a logical collection or container of related database objects. For example, sales tables might be contained in one schema and marketing tables might be contained in another. The top-level navigation point is the query engine. You start by selecting an engine that is associated with the catalog and bucket you want to manage. As there is only one engine in this environment (presto-01), it is selected by default. If this was an environment with multiple engines defined, you would have the choice of selecting any one of the engines you have set up (as the administrator) or that you\u2019ve been given access to (as a non-administrator). With the engine selected, you can now navigate through the catalogs associated with the selected engine (the catalogs are listed in the Catalogs associated section on the left). Currently, this includes the two default catalogs ( hive_data and iceberg_data ) and the system catalog ( wxd_system_data ). Press the \u25ba beside the hive_data catalog to display the schemas in the catalog If the system has not expanded the first schema in the list ( gosalesdw ), click on the gosalesdw schema to display the tables that are associated with that schema. Collapse the gosalesdw schema by pressing the \u25bc icon Your screen may show fewer schemas, but should include gosalesdw , taxi , and ontime in the list. Expand the ontime schema by pressing \u25ba beside the schema name There are 5 tables associated with this schema. Get details of the ontime table by pressing on the table name The ontime table provides details of flight delays for flights within the United States for a one-month period of time. This screen displays the table definition (DDL) for the data. The panel on the right contains additional tabs which provide options for you to view some sample data, and to generate the DDL (Data Definition Language) SQL for the table. Select Data sample tab Select DDL (Data Definition) tab You can use the generated DDL as an SQL statement that can be used to recreate the table. Summary This lab covered the Data Manager menu found in the watsonx.data UI. The Data manager page can be used to explore and curate your data. It includes a data objects navigation pane on the left side of the page with a navigable hierarchy. You learned how to: Explore the catalogs and schemas registered in the system View the structure (definition) of a table View a subset of data in the table Generate the DDL for creating the table The next section will explore the Query workspace and how to issue SQL commands against the tables registered in the system.","title":"Data Manager"},{"location":"wxd-intro-datamanager/#data-manager","text":"The Data manager page can be used to explore and curate your data. It includes a data objects navigation pane on the left side of the page with a navigable hierarchy of engine \u2192 catalog \u2192 schema \u2192 table. Click on the Data Manager icon on the left side of the screen When the Data manager initially starts, you may not see any values on the right-hand side of the screen. This side of the screen is populated when you expand one of the selections on the left side. Watsonx.data (Presto) organizes tables, views, and other database objects in schemas. A schema is a logical collection or container of related database objects. For example, sales tables might be contained in one schema and marketing tables might be contained in another. The top-level navigation point is the query engine. You start by selecting an engine that is associated with the catalog and bucket you want to manage. As there is only one engine in this environment (presto-01), it is selected by default. If this was an environment with multiple engines defined, you would have the choice of selecting any one of the engines you have set up (as the administrator) or that you\u2019ve been given access to (as a non-administrator). With the engine selected, you can now navigate through the catalogs associated with the selected engine (the catalogs are listed in the Catalogs associated section on the left). Currently, this includes the two default catalogs ( hive_data and iceberg_data ) and the system catalog ( wxd_system_data ). Press the \u25ba beside the hive_data catalog to display the schemas in the catalog If the system has not expanded the first schema in the list ( gosalesdw ), click on the gosalesdw schema to display the tables that are associated with that schema. Collapse the gosalesdw schema by pressing the \u25bc icon Your screen may show fewer schemas, but should include gosalesdw , taxi , and ontime in the list. Expand the ontime schema by pressing \u25ba beside the schema name There are 5 tables associated with this schema. Get details of the ontime table by pressing on the table name The ontime table provides details of flight delays for flights within the United States for a one-month period of time. This screen displays the table definition (DDL) for the data. The panel on the right contains additional tabs which provide options for you to view some sample data, and to generate the DDL (Data Definition Language) SQL for the table. Select Data sample tab Select DDL (Data Definition) tab You can use the generated DDL as an SQL statement that can be used to recreate the table.","title":"Data Manager"},{"location":"wxd-intro-datamanager/#summary","text":"This lab covered the Data Manager menu found in the watsonx.data UI. The Data manager page can be used to explore and curate your data. It includes a data objects navigation pane on the left side of the page with a navigable hierarchy. You learned how to: Explore the catalogs and schemas registered in the system View the structure (definition) of a table View a subset of data in the table Generate the DDL for creating the table The next section will explore the Query workspace and how to issue SQL commands against the tables registered in the system.","title":"Summary"},{"location":"wxd-intro-infrastructure/","text":"Infrastructure Manager The Infrastructure manager page opens with a graphical canvas view of the different infrastructure components currently defined in this watsonx.data environment. Before describing the contents of the UI, some explanation of the watsonx.data objects are necessary. Watsonx.data is based on open-source Presto DB, a distributed query engine that enables querying data stored in open file formats using open table formats for optimization and performance. There are four types of objects that are commonly referred to in the Presto DB environment: Engine \u2013 Each watsonx.data installation has at least one Presto DB engine which is used for querying the data. An installation can have more than one Presto engine to improve performance, isolate workloads, or test different versions. Additional engines can include Apache Spark, which provides capabilities for reading and transforming many types of data. Catalogs \u2013 Catalogs contain information about tables, files, and objects that are found in databases or file systems. Catalogs can be specific to the type of object being manipulated (Apache Hive, Apache Iceberg). Buckets \u2013 Buckets refer to Cloud Object Storage (MinIO, AWS S3, IBM COS, etc...) that contain the files and objects that you will catalog and eventually query with an engine. Database \u2013 These represent 3rd party databases that are used to query tables that are in a vendor\u2019s proprietary format (Oracle, Db2, Netezza, etc...). Services - Services refer to additional components in watsonx.data (like Milvus) which provide specific features that are not found in the watsonx.data engine itself. There are two built-in catalogs provided with watsonx.data: Hive_data \u2013 This catalog contains references to objects that are immutable. These are objects such as CSV (comma-separated values), Text, JSON, and Apache Parquet files which are read-only. Iceberg_data \u2013 This catalog contains references to tables that are in Apache Iceberg format. These tables are optimized for space usage and query performance and can be updated. Now that you know what the various components are, we can look at the information found in the Infrastructure manager. Infrastructure Manager UI The Infrastructure manager page opens with a graphical canvas view of the different infrastructure components currently defined in this watsonx.data environment. Click on the Infrastructure icon on the left side of the screen The Infrastructure manager provides a helpful visualization of the current system. These components are: Engines (blue layer) \u2013 The query engines that will access the data. Catalogs (purple layer) \u2013 Catalogs contain metadata about the objects found in buckets or databases. Each catalog is associated with one or more engines. An engine can\u2019t access data in a bucket or a remote database unless the corresponding catalog is associated with the engine. Buckets (pink layer) \u2013 An object-store that contains data (i.e., MinIO, AWS S3, Cloud-Object Storage). Each bucket is associated with a catalog (with a 1:1 mapping). When a bucket is added to watsonx.data, a catalog is created for it at the same time, based on input from the user. Databases (blue layer) \u2013 Specialty Database engines. If a database connection is added (for federation purposes), a catalog is created for that database connection as well. Services (green layer) - Specialty Services. In this system, a Milvus Vector database has been provisioned as an extra service. The diagram can become complex as the number of data sources and engines increases. You can use the magnifier in the bottom right corner to fit the diagram onto the screen or to focus in on a portion of the diagram. You have the option of auto-arranging, zooming in, zooming out, or fitting the diagram to the screen. Click on the Zoom out (-) button and then Zoom in (+) The following is an example of a complex system where the diagram was fit to the screen. You can also use your mouse to click on part of the screen and \u201cmove\u201d it to center the diagram. To reduce the objects on the screen, you can filter them by object type using the filter icon: Filter by Catalogs to view the three catalogs that exist in the system To reset the screen back to the full diagram, choose reset in the filter dialog. Reset the Filters You can view the Infrastructure diagram as table by selecting the list view icon at the top right of the screen. Select List View Selecting the list icon will display the system as a table with a separate tab for Engines, Catalogs, Buckets, and Databases. Click on each tab in the table view to see the contents Reset back to the topology view. Switch back to topology view to the show the entire diagram Exploring the Contents of a Catalog Hover your mouse over the hive_data catalog As you hover your mouse over the hive_data catalog in the topology view, the elements (engine, catalogs, buckets, databases) that are connected will be highlighted on the screen. To explore the contents of the hive_data catalog, click on the catalog icon. Click on the hive_data catalog icon Detailed information about the catalog is displayed on the screen. There are additional tabs at the top of the screen that provide information on the data objects that are cataloged and the access control for those objects. Click on the Data Objects tab The Data Objects tab provides detailed information on the contents of the catalog. This provides an easy way to explore the contents of the catalog. Click on the Access Control Tab The access control tab provides a list of users and groups that are authorized to access this bucket. The system currently has two registered users in it (your system may have only one). Close the dialog by pressing the [x] in the corner, or using the Escape key You should now see the topology view of the system. Exploring the Contents of a Bucket Hover your mouse over the hive_data bucket Instead of selecting the catalog, click on the hive-bucket at the bottom of the screen. Watsonx.data is a unified analytics repository, and it starts like most data management solutions with storage. The most pervasive storage solution in the marketplace is object store. There are several solutions in the marketplace providing low cost, unlimited scalability, extreme durability, and high throughput. The Developer edition of watsonx.data uses MinIO as an S3-complaint object store. The bucket hive-bucket resides in MinIO storage and is cataloged in watsonx.data. There are three additional buckets, iceberg-bucket used to store Iceberg tables, wxd-system used for control information, and wxd-milvus for Milvus vector database storage. There are three tabs in the bucket details pane: Details Objects Access Control Click on the Objects tab The objects tab provides a view into the physical files that are found in the bucket. There is a hierarchy of directories that make up the contents of the bucket. At the highest level we have the bucket itself, or hive-bucket in this example. The bucket contains a number of directories: gosales, ontime, taxi, and hive_sql. The display will indicate the number of directories or files that are found in the directory. This first level of directories map to the schema name. In the watsonx.data system, the schema ontime has the tables cataloged underneath the ontime directory. Click on the ontime directory The directories in this panel map to the table names. For instance, the directory aircraft is used to store the aircraft table. Click on the aircraft directory The physical file that is used to represent the aircraft types is found in this file. An iceberg table will include additional information containing versioning, statistics and partitioning of the table. Close the bucket dialog by pressing the [x] in the corner Summary The Infrastructure view provides a way to visualize the topology of the watsonx.data system. The topology includes: Engines (blue layer) \u2013 The query engines that will access the data. Catalogs (purple layer) \u2013 Catalogs contain metadata about the objects found in buckets or databases. Storage (red layer) \u2013 An object-store that contains data (i.e., MinIO, AWS S3, Cloud-Object Storage). Databases (blue layer) \u2013 Specialty Database engines. Services (green layer) - Services like Milvus The Infrastructure view allows an administrator to add Engines, Catalogs, Buckets, and Databases to the system. In addition, the individual objects can be selected to view the definition, contents, and access control.","title":"Infrastructure Manager"},{"location":"wxd-intro-infrastructure/#infrastructure-manager","text":"The Infrastructure manager page opens with a graphical canvas view of the different infrastructure components currently defined in this watsonx.data environment. Before describing the contents of the UI, some explanation of the watsonx.data objects are necessary. Watsonx.data is based on open-source Presto DB, a distributed query engine that enables querying data stored in open file formats using open table formats for optimization and performance. There are four types of objects that are commonly referred to in the Presto DB environment: Engine \u2013 Each watsonx.data installation has at least one Presto DB engine which is used for querying the data. An installation can have more than one Presto engine to improve performance, isolate workloads, or test different versions. Additional engines can include Apache Spark, which provides capabilities for reading and transforming many types of data. Catalogs \u2013 Catalogs contain information about tables, files, and objects that are found in databases or file systems. Catalogs can be specific to the type of object being manipulated (Apache Hive, Apache Iceberg). Buckets \u2013 Buckets refer to Cloud Object Storage (MinIO, AWS S3, IBM COS, etc...) that contain the files and objects that you will catalog and eventually query with an engine. Database \u2013 These represent 3rd party databases that are used to query tables that are in a vendor\u2019s proprietary format (Oracle, Db2, Netezza, etc...). Services - Services refer to additional components in watsonx.data (like Milvus) which provide specific features that are not found in the watsonx.data engine itself. There are two built-in catalogs provided with watsonx.data: Hive_data \u2013 This catalog contains references to objects that are immutable. These are objects such as CSV (comma-separated values), Text, JSON, and Apache Parquet files which are read-only. Iceberg_data \u2013 This catalog contains references to tables that are in Apache Iceberg format. These tables are optimized for space usage and query performance and can be updated. Now that you know what the various components are, we can look at the information found in the Infrastructure manager.","title":"Infrastructure Manager"},{"location":"wxd-intro-infrastructure/#infrastructure-manager-ui","text":"The Infrastructure manager page opens with a graphical canvas view of the different infrastructure components currently defined in this watsonx.data environment. Click on the Infrastructure icon on the left side of the screen The Infrastructure manager provides a helpful visualization of the current system. These components are: Engines (blue layer) \u2013 The query engines that will access the data. Catalogs (purple layer) \u2013 Catalogs contain metadata about the objects found in buckets or databases. Each catalog is associated with one or more engines. An engine can\u2019t access data in a bucket or a remote database unless the corresponding catalog is associated with the engine. Buckets (pink layer) \u2013 An object-store that contains data (i.e., MinIO, AWS S3, Cloud-Object Storage). Each bucket is associated with a catalog (with a 1:1 mapping). When a bucket is added to watsonx.data, a catalog is created for it at the same time, based on input from the user. Databases (blue layer) \u2013 Specialty Database engines. If a database connection is added (for federation purposes), a catalog is created for that database connection as well. Services (green layer) - Specialty Services. In this system, a Milvus Vector database has been provisioned as an extra service. The diagram can become complex as the number of data sources and engines increases. You can use the magnifier in the bottom right corner to fit the diagram onto the screen or to focus in on a portion of the diagram. You have the option of auto-arranging, zooming in, zooming out, or fitting the diagram to the screen. Click on the Zoom out (-) button and then Zoom in (+) The following is an example of a complex system where the diagram was fit to the screen. You can also use your mouse to click on part of the screen and \u201cmove\u201d it to center the diagram. To reduce the objects on the screen, you can filter them by object type using the filter icon: Filter by Catalogs to view the three catalogs that exist in the system To reset the screen back to the full diagram, choose reset in the filter dialog. Reset the Filters You can view the Infrastructure diagram as table by selecting the list view icon at the top right of the screen. Select List View Selecting the list icon will display the system as a table with a separate tab for Engines, Catalogs, Buckets, and Databases. Click on each tab in the table view to see the contents Reset back to the topology view. Switch back to topology view to the show the entire diagram","title":"Infrastructure Manager UI"},{"location":"wxd-intro-infrastructure/#exploring-the-contents-of-a-catalog","text":"Hover your mouse over the hive_data catalog As you hover your mouse over the hive_data catalog in the topology view, the elements (engine, catalogs, buckets, databases) that are connected will be highlighted on the screen. To explore the contents of the hive_data catalog, click on the catalog icon. Click on the hive_data catalog icon Detailed information about the catalog is displayed on the screen. There are additional tabs at the top of the screen that provide information on the data objects that are cataloged and the access control for those objects. Click on the Data Objects tab The Data Objects tab provides detailed information on the contents of the catalog. This provides an easy way to explore the contents of the catalog. Click on the Access Control Tab The access control tab provides a list of users and groups that are authorized to access this bucket. The system currently has two registered users in it (your system may have only one). Close the dialog by pressing the [x] in the corner, or using the Escape key You should now see the topology view of the system.","title":"Exploring the Contents of a Catalog"},{"location":"wxd-intro-infrastructure/#exploring-the-contents-of-a-bucket","text":"Hover your mouse over the hive_data bucket Instead of selecting the catalog, click on the hive-bucket at the bottom of the screen. Watsonx.data is a unified analytics repository, and it starts like most data management solutions with storage. The most pervasive storage solution in the marketplace is object store. There are several solutions in the marketplace providing low cost, unlimited scalability, extreme durability, and high throughput. The Developer edition of watsonx.data uses MinIO as an S3-complaint object store. The bucket hive-bucket resides in MinIO storage and is cataloged in watsonx.data. There are three additional buckets, iceberg-bucket used to store Iceberg tables, wxd-system used for control information, and wxd-milvus for Milvus vector database storage. There are three tabs in the bucket details pane: Details Objects Access Control Click on the Objects tab The objects tab provides a view into the physical files that are found in the bucket. There is a hierarchy of directories that make up the contents of the bucket. At the highest level we have the bucket itself, or hive-bucket in this example. The bucket contains a number of directories: gosales, ontime, taxi, and hive_sql. The display will indicate the number of directories or files that are found in the directory. This first level of directories map to the schema name. In the watsonx.data system, the schema ontime has the tables cataloged underneath the ontime directory. Click on the ontime directory The directories in this panel map to the table names. For instance, the directory aircraft is used to store the aircraft table. Click on the aircraft directory The physical file that is used to represent the aircraft types is found in this file. An iceberg table will include additional information containing versioning, statistics and partitioning of the table. Close the bucket dialog by pressing the [x] in the corner","title":"Exploring the Contents of a Bucket"},{"location":"wxd-intro-infrastructure/#summary","text":"The Infrastructure view provides a way to visualize the topology of the watsonx.data system. The topology includes: Engines (blue layer) \u2013 The query engines that will access the data. Catalogs (purple layer) \u2013 Catalogs contain metadata about the objects found in buckets or databases. Storage (red layer) \u2013 An object-store that contains data (i.e., MinIO, AWS S3, Cloud-Object Storage). Databases (blue layer) \u2013 Specialty Database engines. Services (green layer) - Services like Milvus The Infrastructure view allows an administrator to add Engines, Catalogs, Buckets, and Databases to the system. In addition, the individual objects can be selected to view the definition, contents, and access control.","title":"Summary"},{"location":"wxd-intro-queryworkspace/","text":"Query Workspace Databases and query engines such as Presto have multiple ways that users can interact with the data. For example, there is usually an interactive command line interface (CLI) that lets users run SQL statements from a command terminal. Applications can use JDBC (Java Database Connectivity) to connect to the data store and run SQL statements. The watsonx.data user interface includes an SQL interface for building and running SQL statements. This is called the Query workspace. Users can write or copy in their own SQL statements, or they can use templates to assist in building new SQL statements. Click on the Query Workspace icon on the left side of the screen The Query workspace will have a similar layout to the Data Manager screen, where you can navigate through the catalogs associated with the selected engine. The SQL work area is found to the right of the catalog and table names. You can type, paste, or use saved workspaces to enter SQL (Structured Query Language) commands into this window. An SQL statement instructs the database engine what records to look for in one or more tables. The Query workspace provides several pre-built SQL statements that can be generated for tables already cataloged in the system. In the Data Manager lab, the Data sample tab was used to view a subset of the data in the airline_delay_cause table. This data can be generated in the Query Workspace window by using a prebuilt SQL generator. Expand the hive_data catalog by clicking on the \u25ba beside the hive_data name You should now see all the schemas associated with the catalog, including the ontime schema. Expand the ontime schema by pressing \u25ba beside the schema name The ontime schema includes 5 tables. Hover your mouse over the ontime table name When your mouse hovers over a table name, two icons will become visible. The first icon the refresh symbol \u21ba . The refresh icon forces the watsonx.data UI to retrieve details about the schema or table. Note that watsonx.data does not always reflect the status of tables in the display. The refresh process in not synchronous (i.e., it does not know that an update may have occurred to a table), so changes are not immediately shown in the display. The second icon </> is used to display query templates. Click on the query template icon when it appears on the ontime table line The menu provides four templates for your table: Generate Path \u2013 The path description (or location) of the object. Generate Select \u2013 An SQL statement that will return the contents of the table. Generate Alter \u2013 An SQL statement (DDL \u2013 Data Definition Language) used to alter characteristics of the table, like adding a column. Generate Drop \u2013 An SQL statement used to remove the object from the system. Select the Generate SELECT option The system has populated the SQL window with the catalog name, the schema and the table name. This SQL will retrieve all the columns of the table and limit the output to 10 rows (LIMIT 10). The Run on presto-01 button is highlighted at the far right of the SQL window. The button will reflect which engine watsonx.data will run your query on. There is a pulldown menu beside the button that provides an option to run the query to the point where your cursor is on the text, or from where your cursor is on the text. You can use these options to run portions of an SQL statement when you are debugging results. In this instance, you just want to run the query and display the results. Press the Run on presto-01 button and wait for the results to return Near the middle of the screen, you will see the statement that was executed, the run time, and the success or failure of the statement. The result set (if there is one) is displayed below the SQL statement. An export icon \u2913 is found on the far-right side of the result set. Clicking on the export icon will download the results as a CSV file on your workstation. Select the Details tab in the result set window This dialog provides more information on the execution of the SQL statement. If you want additional details on the query execution plan, you can press the Explain button beside the Run on presto-01 button. Press the Explain button in the SQL window The graph displays the steps the Presto engine took to compute the answer. You can click on any one of the boxes in the diagram to display the details of the step. The system will not show many details because the data is in a hive catalog and not optimized for retrieval. Close the Explain dialog by pressing the [x] If you find that you are running the same SQL repeatedly, you can save the SQL as a worksheet. The SQL window should still have your select statement that was generated to retrieve the first 10 rows of the table. The save button is found above the SQL. Press the save button The Save icon will open a dialog to save the SQL statement. Enter the name Quick Look and press the Save button At the bottom of your catalog and table list you will see a list of saved worksheets. In there should be the one you just saved called Quick Look . If you do not see your file, refresh your browser window Open a new SQL tab [+] and then click on the Quick Look worksheet you created When you click on the name of a worksheet, the SQL will be placed into the current tab in the SQL window, with the tab containing the name of your saved worksheet. You can now modify the SQL before running it to retrieve results. Summary This chapter explored the use of the Query Workspace to run SQL commands, generate queries, and determine how the optimizer ran a query. In addition, the ability to store and retrieve SQL was used.","title":"Query Workspace"},{"location":"wxd-intro-queryworkspace/#query-workspace","text":"Databases and query engines such as Presto have multiple ways that users can interact with the data. For example, there is usually an interactive command line interface (CLI) that lets users run SQL statements from a command terminal. Applications can use JDBC (Java Database Connectivity) to connect to the data store and run SQL statements. The watsonx.data user interface includes an SQL interface for building and running SQL statements. This is called the Query workspace. Users can write or copy in their own SQL statements, or they can use templates to assist in building new SQL statements. Click on the Query Workspace icon on the left side of the screen The Query workspace will have a similar layout to the Data Manager screen, where you can navigate through the catalogs associated with the selected engine. The SQL work area is found to the right of the catalog and table names. You can type, paste, or use saved workspaces to enter SQL (Structured Query Language) commands into this window. An SQL statement instructs the database engine what records to look for in one or more tables. The Query workspace provides several pre-built SQL statements that can be generated for tables already cataloged in the system. In the Data Manager lab, the Data sample tab was used to view a subset of the data in the airline_delay_cause table. This data can be generated in the Query Workspace window by using a prebuilt SQL generator. Expand the hive_data catalog by clicking on the \u25ba beside the hive_data name You should now see all the schemas associated with the catalog, including the ontime schema. Expand the ontime schema by pressing \u25ba beside the schema name The ontime schema includes 5 tables. Hover your mouse over the ontime table name When your mouse hovers over a table name, two icons will become visible. The first icon the refresh symbol \u21ba . The refresh icon forces the watsonx.data UI to retrieve details about the schema or table. Note that watsonx.data does not always reflect the status of tables in the display. The refresh process in not synchronous (i.e., it does not know that an update may have occurred to a table), so changes are not immediately shown in the display. The second icon </> is used to display query templates. Click on the query template icon when it appears on the ontime table line The menu provides four templates for your table: Generate Path \u2013 The path description (or location) of the object. Generate Select \u2013 An SQL statement that will return the contents of the table. Generate Alter \u2013 An SQL statement (DDL \u2013 Data Definition Language) used to alter characteristics of the table, like adding a column. Generate Drop \u2013 An SQL statement used to remove the object from the system. Select the Generate SELECT option The system has populated the SQL window with the catalog name, the schema and the table name. This SQL will retrieve all the columns of the table and limit the output to 10 rows (LIMIT 10). The Run on presto-01 button is highlighted at the far right of the SQL window. The button will reflect which engine watsonx.data will run your query on. There is a pulldown menu beside the button that provides an option to run the query to the point where your cursor is on the text, or from where your cursor is on the text. You can use these options to run portions of an SQL statement when you are debugging results. In this instance, you just want to run the query and display the results. Press the Run on presto-01 button and wait for the results to return Near the middle of the screen, you will see the statement that was executed, the run time, and the success or failure of the statement. The result set (if there is one) is displayed below the SQL statement. An export icon \u2913 is found on the far-right side of the result set. Clicking on the export icon will download the results as a CSV file on your workstation. Select the Details tab in the result set window This dialog provides more information on the execution of the SQL statement. If you want additional details on the query execution plan, you can press the Explain button beside the Run on presto-01 button. Press the Explain button in the SQL window The graph displays the steps the Presto engine took to compute the answer. You can click on any one of the boxes in the diagram to display the details of the step. The system will not show many details because the data is in a hive catalog and not optimized for retrieval. Close the Explain dialog by pressing the [x] If you find that you are running the same SQL repeatedly, you can save the SQL as a worksheet. The SQL window should still have your select statement that was generated to retrieve the first 10 rows of the table. The save button is found above the SQL. Press the save button The Save icon will open a dialog to save the SQL statement. Enter the name Quick Look and press the Save button At the bottom of your catalog and table list you will see a list of saved worksheets. In there should be the one you just saved called Quick Look . If you do not see your file, refresh your browser window Open a new SQL tab [+] and then click on the Quick Look worksheet you created When you click on the name of a worksheet, the SQL will be placed into the current tab in the SQL window, with the tab containing the name of your saved worksheet. You can now modify the SQL before running it to retrieve results.","title":"Query Workspace"},{"location":"wxd-intro-queryworkspace/#summary","text":"This chapter explored the use of the Query Workspace to run SQL commands, generate queries, and determine how the optimizer ran a query. In addition, the ability to store and retrieve SQL was used.","title":"Summary"},{"location":"wxd-intro-watsonui/","text":"Watsonx.data Console UI Overview Your TechZone reservation will include the server name and port number to use when connecting to the watsonx.data UI. Watsonx UI - https://na4.services.cloud.techzone.ibm.com:xxxxx Click on the watsonx.data UI supplied link or copy the URL and port number into your browser The watsonx.data UI will display with a login prompt. Enter the credentials for the ibmlhadmin user and press Log in Username: ibmlhadmin Password: password After entering the userid and password, the main watsonx.data UI will be displayed. Watsonx.data UI Navigation The main screen provides a snapshot of the objects that are currently found in the watsonx.data system. The infrastructure display shows that there is 1 engine, 3 catalogs, 4 buckets, and no databases associated with the system. You can examine these objects by using the menu system found on the left side of the screen. Click on the hamburger icon This will provide a list of items that you can explore in the UI. You can also access this list by clicking on one of the following icons. A brief description of the items is found below. Display the Home page. Infrastructure Manager \u2013 Displays the current engines, buckets and databases associated with the installation. Data Manager \u2013 Used to explore the various data sources that are cataloged in the system. You can explore the schemas, tables, table layout and view a subset of the data with this option. Query Workspace \u2013 An SQL-based query tool for accessing the data. Query History \u2013 A list of SQL queries that were previously run across all engines. Access Control \u2013 Control who can access the data. Home Page Displays a summary of the watsonx.data system and provides a summary of recent activity in the system. Infrastructure manager The Infrastructure manager displays the current engines, buckets and databases associated with the installation. Click on the Infrastructure Manager icon Data Manager The Data Manager is used to explore the various data sources that are cataloged in the system. You can explore the schemas, tables, table layout and view a subset of the data with this option. The display make take a few minutes to show the schemas in the system as it is querying the catalog and populating the descriptions on the screen. Click on the Data Manager icon Query Workplace The Query Workspace provides an SQL-based query tool for accessing the data. Click on the Query Workplace icon Query History The Query History displays a list of SQL queries that were previously run across all engines. Click on the Query History icon Access Control The Access Control dialog provides controls for who can access the data. Click on the Access Control icon The Developer Edition does not provide the ability to add or remove users from the Access Control panel. The full version of watsonx.data does provide this capability. Add and removing users can be done through a command line interface instead. Summary In this section you learned how to display the watsonx.data UI. You then explored some of the menu items that are found in the watsonx.data UI itself. The subsequent sections will explore the following menu items: Infrastructure Manager Data Manager Query Workspace The next section will examine the Infrastructure Manager and how it provides a graphical view of the watsonx.data system.","title":"Watsonx UI Overview"},{"location":"wxd-intro-watsonui/#watsonxdata-console-ui-overview","text":"Your TechZone reservation will include the server name and port number to use when connecting to the watsonx.data UI. Watsonx UI - https://na4.services.cloud.techzone.ibm.com:xxxxx Click on the watsonx.data UI supplied link or copy the URL and port number into your browser The watsonx.data UI will display with a login prompt. Enter the credentials for the ibmlhadmin user and press Log in Username: ibmlhadmin Password: password After entering the userid and password, the main watsonx.data UI will be displayed.","title":"Watsonx.data Console UI Overview"},{"location":"wxd-intro-watsonui/#watsonxdata-ui-navigation","text":"The main screen provides a snapshot of the objects that are currently found in the watsonx.data system. The infrastructure display shows that there is 1 engine, 3 catalogs, 4 buckets, and no databases associated with the system. You can examine these objects by using the menu system found on the left side of the screen. Click on the hamburger icon This will provide a list of items that you can explore in the UI. You can also access this list by clicking on one of the following icons. A brief description of the items is found below. Display the Home page. Infrastructure Manager \u2013 Displays the current engines, buckets and databases associated with the installation. Data Manager \u2013 Used to explore the various data sources that are cataloged in the system. You can explore the schemas, tables, table layout and view a subset of the data with this option. Query Workspace \u2013 An SQL-based query tool for accessing the data. Query History \u2013 A list of SQL queries that were previously run across all engines. Access Control \u2013 Control who can access the data.","title":"Watsonx.data UI Navigation"},{"location":"wxd-intro-watsonui/#home-page","text":"Displays a summary of the watsonx.data system and provides a summary of recent activity in the system.","title":"Home Page"},{"location":"wxd-intro-watsonui/#infrastructure-manager","text":"The Infrastructure manager displays the current engines, buckets and databases associated with the installation. Click on the Infrastructure Manager icon","title":"Infrastructure manager"},{"location":"wxd-intro-watsonui/#data-manager","text":"The Data Manager is used to explore the various data sources that are cataloged in the system. You can explore the schemas, tables, table layout and view a subset of the data with this option. The display make take a few minutes to show the schemas in the system as it is querying the catalog and populating the descriptions on the screen. Click on the Data Manager icon","title":"Data Manager"},{"location":"wxd-intro-watsonui/#query-workplace","text":"The Query Workspace provides an SQL-based query tool for accessing the data. Click on the Query Workplace icon","title":"Query Workplace"},{"location":"wxd-intro-watsonui/#query-history","text":"The Query History displays a list of SQL queries that were previously run across all engines. Click on the Query History icon","title":"Query History"},{"location":"wxd-intro-watsonui/#access-control","text":"The Access Control dialog provides controls for who can access the data. Click on the Access Control icon The Developer Edition does not provide the ability to add or remove users from the Access Control panel. The full version of watsonx.data does provide this capability. Add and removing users can be done through a command line interface instead.","title":"Access Control"},{"location":"wxd-intro-watsonui/#summary","text":"In this section you learned how to display the watsonx.data UI. You then explored some of the menu items that are found in the watsonx.data UI itself. The subsequent sections will explore the following menu items: Infrastructure Manager Data Manager Query Workspace The next section will examine the Infrastructure Manager and how it provides a graphical view of the watsonx.data system.","title":"Summary"},{"location":"wxd-introduction/","text":"RAG Generation with watsonx.data and Milvus The next-gen watsonx.data lakehouse is designed to overcome the costs and complexities enterprises face. This will be the world\u2019s first and only open data store with multi-engine support that is built for hybrid deployment across your entire ecosystem. IBM watsonx.data is the only lakehouse with multiple query engines allowing you to optimize costs and performance by pairing the right workload with the right engine. Run all workloads from a single pane of glass, eliminating trade-offs with convenience while still improving cost and performance. Deploy anywhere with full support for hybrid-cloud and multi cloud environments. Shared metadata across multiple engines eliminates the need to re-catalog, accelerating time to value while ensuring governance and eliminating costly implementation efforts. Overview This system demonstrates the use of watsonx.data, Milvus, and the use of the IBM Instructlab Granite model to answer questions regarding a variety of topics. The system has a built-in example of creating a RAG prompt from the IBM web site. You can add additional content to the system to try other scenarios with the system. The system is designed around five steps: The watsonx.data product is used to store control information and the raw documents (PDF, Powerpoint, URLs). The Milvus vector database contains vectors that are built from the raw documents stored in the watsonx.data database. A prompt is generated from the question that is supplied by querying the Milvus database for the document segments that best match the request. The prompt is sent to an AI engine to process. This process is done locally in this system using Ollama. Since there are no GPUs in this system, performance will be slow. The answer is returned to the user Start by importing documents, web sites, or articles from Wikipedia into the system. As a starter document, the IBM 2023 annual report summary has been preloaded. You can ask questions about the earnings to see how the LLM answers your question. An example would be to ask the LLM \"What were IBMs earning in 2023\" without using RAG and then ask the question again using RAG . This provides a comparison of the types of responses you may get from an LLM. Once you have imported one or more documents, you must select which ones to vectorize. The documents will be split into chunks which are then stored and vectorized into the Milvus database. These chunks will be used to generate the RAG prompt when you query the LLM. The Query LLM page will provide an interface for asking questions to the LLM. There are additional settings here which lets you change the LLM that is being used (the IBM instructlab/granite-7b-lab model is the default). Each LLM will behave differently so it is often an interesting exercise to try the same questions with different models. You can set whether or not a RAG prompt is generated as part of your query, as well as adjust how many sentence chunks from the vector database will be used to construct the prompt. If you want to try a different LLM, you can use the Add LLM panel to load an LLM found in the Ollama or Hugging Face library. The load step will download the model to the local server and then make it available as an LLM that you can ask questions of. If you find that the system is not being responsive, you may want to check the Diagnostics page to see if the watsonx.data services are running. You can restart many of the services from this dialog. In addition, the Log file may provide more details on what went wrong. Finally, details about this system and the programs that were used to create this are listed in the Support section. Remember that this system does not contain GPUs which limits the performance of the LLM. However, it does provide an environment to try out RAG prompts and observe how different LLMs behave with and without RAG prompts.","title":"Introduction"},{"location":"wxd-introduction/#rag-generation-with-watsonxdata-and-milvus","text":"The next-gen watsonx.data lakehouse is designed to overcome the costs and complexities enterprises face. This will be the world\u2019s first and only open data store with multi-engine support that is built for hybrid deployment across your entire ecosystem. IBM watsonx.data is the only lakehouse with multiple query engines allowing you to optimize costs and performance by pairing the right workload with the right engine. Run all workloads from a single pane of glass, eliminating trade-offs with convenience while still improving cost and performance. Deploy anywhere with full support for hybrid-cloud and multi cloud environments. Shared metadata across multiple engines eliminates the need to re-catalog, accelerating time to value while ensuring governance and eliminating costly implementation efforts.","title":"RAG Generation with watsonx.data and Milvus"},{"location":"wxd-introduction/#overview","text":"This system demonstrates the use of watsonx.data, Milvus, and the use of the IBM Instructlab Granite model to answer questions regarding a variety of topics. The system has a built-in example of creating a RAG prompt from the IBM web site. You can add additional content to the system to try other scenarios with the system. The system is designed around five steps: The watsonx.data product is used to store control information and the raw documents (PDF, Powerpoint, URLs). The Milvus vector database contains vectors that are built from the raw documents stored in the watsonx.data database. A prompt is generated from the question that is supplied by querying the Milvus database for the document segments that best match the request. The prompt is sent to an AI engine to process. This process is done locally in this system using Ollama. Since there are no GPUs in this system, performance will be slow. The answer is returned to the user Start by importing documents, web sites, or articles from Wikipedia into the system. As a starter document, the IBM 2023 annual report summary has been preloaded. You can ask questions about the earnings to see how the LLM answers your question. An example would be to ask the LLM \"What were IBMs earning in 2023\" without using RAG and then ask the question again using RAG . This provides a comparison of the types of responses you may get from an LLM. Once you have imported one or more documents, you must select which ones to vectorize. The documents will be split into chunks which are then stored and vectorized into the Milvus database. These chunks will be used to generate the RAG prompt when you query the LLM. The Query LLM page will provide an interface for asking questions to the LLM. There are additional settings here which lets you change the LLM that is being used (the IBM instructlab/granite-7b-lab model is the default). Each LLM will behave differently so it is often an interesting exercise to try the same questions with different models. You can set whether or not a RAG prompt is generated as part of your query, as well as adjust how many sentence chunks from the vector database will be used to construct the prompt. If you want to try a different LLM, you can use the Add LLM panel to load an LLM found in the Ollama or Hugging Face library. The load step will download the model to the local server and then make it available as an LLM that you can ask questions of. If you find that the system is not being responsive, you may want to check the Diagnostics page to see if the watsonx.data services are running. You can restart many of the services from this dialog. In addition, the Log file may provide more details on what went wrong. Finally, details about this system and the programs that were used to create this are listed in the Support section. Remember that this system does not contain GPUs which limits the performance of the LLM. However, it does provide an environment to try out RAG prompts and observe how different LLMs behave with and without RAG prompts.","title":"Overview"},{"location":"wxd-milvus/","text":"Milvus Milvus is a vector database that stores, indexes, and manages massive embedding vectors that are developed by deep neural networks and other machine learning (ML) models. It is developed to empower embedding similarity search and AI applications. Milvus makes unstructured data search more accessible and consistent across various environments. Local Milvus Connection A watsonx.data system that you are running includes the Milvus server. The userid for connecting to the Milvus service is the default watsonx.data userid (ibmlhadmin).","title":"Milvus"},{"location":"wxd-milvus/#milvus","text":"Milvus is a vector database that stores, indexes, and manages massive embedding vectors that are developed by deep neural networks and other machine learning (ML) models. It is developed to empower embedding similarity search and AI applications. Milvus makes unstructured data search more accessible and consistent across various environments.","title":"Milvus"},{"location":"wxd-milvus/#local-milvus-connection","text":"A watsonx.data system that you are running includes the Milvus server. The userid for connecting to the Milvus service is the default watsonx.data userid (ibmlhadmin).","title":"Local Milvus Connection"},{"location":"wxd-reference-access/","text":"Accessing the watsonx.data TechZone Image The reservation email from TechZone is extremely important since it provides a link to your reservation. Click on the View My Reservations to access your reservations. Click on the reservation that corresponds to the watsonx.data reservation. The menu button that is beside the arrow provides options to extend or delete the reservation. When you click on reservation details option, or the Open this Environment box, the browser will display the details of your image. The top of the reservation will display two URLs which will be used to access the demonstration system. The first link is used to access the demo program, while the second is used to access the watsonx.data console. Details on how to use these are found in the next section. Passwords This table lists the passwords for the services in the system. Service Userid Password Virtual Machine watsonx watsonx.data Virtual Machine root watsonx.data watsonx.data UI ibmlhadmin password Demonstration UI watsonx watsonx.data","title":"Accessing the reservation"},{"location":"wxd-reference-access/#accessing-the-watsonxdata-techzone-image","text":"The reservation email from TechZone is extremely important since it provides a link to your reservation. Click on the View My Reservations to access your reservations. Click on the reservation that corresponds to the watsonx.data reservation. The menu button that is beside the arrow provides options to extend or delete the reservation. When you click on reservation details option, or the Open this Environment box, the browser will display the details of your image. The top of the reservation will display two URLs which will be used to access the demonstration system. The first link is used to access the demo program, while the second is used to access the watsonx.data console. Details on how to use these are found in the next section.","title":"Accessing the watsonx.data TechZone Image"},{"location":"wxd-reference-access/#passwords","text":"This table lists the passwords for the services in the system. Service Userid Password Virtual Machine watsonx watsonx.data Virtual Machine root watsonx.data watsonx.data UI ibmlhadmin password Demonstration UI watsonx watsonx.data","title":"Passwords"},{"location":"wxd-reference-documentation/","text":"Documentation The following links provide more information on the components in this lab. System Software Watsonx.data 2.0.2 - IBM Data Lakehouse environment Presto 0.286 - Database engine used to query data in the lakehouse Milvus - Vector database included in watsonx.data Ollama - Platform for running LLMs locally Application Libraries Streamlit - Web interface framework Llama Index - Data framework for building LLM applications pyMilvus - Python SDK of Milvus prestodb - Presto client langchain - LangChain is a framework designed to simplify LLM applications sqlalchemy - SQLAlchemy is an Object Relational Mapper for database interactions sentence_transformer - Sentence Transformers provides modules for accessing, using, and training embedded models pandas - pandas provides data structures designed to work with relational or tabular data","title":"Documentation"},{"location":"wxd-reference-documentation/#documentation","text":"The following links provide more information on the components in this lab. System Software Watsonx.data 2.0.2 - IBM Data Lakehouse environment Presto 0.286 - Database engine used to query data in the lakehouse Milvus - Vector database included in watsonx.data Ollama - Platform for running LLMs locally Application Libraries Streamlit - Web interface framework Llama Index - Data framework for building LLM applications pyMilvus - Python SDK of Milvus prestodb - Presto client langchain - LangChain is a framework designed to simplify LLM applications sqlalchemy - SQLAlchemy is an Object Relational Mapper for database interactions sentence_transformer - Sentence Transformers provides modules for accessing, using, and training embedded models pandas - pandas provides data structures designed to work with relational or tabular data","title":"Documentation"},{"location":"wxd-reference-passwords/","text":"Passwords This table lists the passwords for the services in the system. Service Userid Password Virtual Machine watsonx watsonx.data Virtual Machine root watsonx.data watsonx.data UI ibmlhadmin password Demonstration UI watsonx watsonx.data","title":"Userids and Passwords"},{"location":"wxd-reference-passwords/#passwords","text":"This table lists the passwords for the services in the system. Service Userid Password Virtual Machine watsonx watsonx.data Virtual Machine root watsonx.data watsonx.data UI ibmlhadmin password Demonstration UI watsonx watsonx.data","title":"Passwords"},{"location":"wxd-reference-ports/","text":"Watsonx.data and Demonstration Ports The top of your TechZone reservation will contain two published services at the top of the details page. These URLs and Port numbers are needed to access the demo. The list will contain the following information: IBM watsonx.data and Milvus Demo: http://region.services.cloud.techzone.ibm.com:33333 Watsonx UI: https://region.services.cloud.techzone.ibm.com:41311 The server URL will be different for each region and data center that your machine is provisioned on. The server name is usually in the format: region.services.cloud.techzone.ibm.com:port The port number that is provided in the reservation is mapped to the proper port number in the server. These links may result in a Certificate error in Firefox. Follow these steps to ignore the error when accessing these URLs. Select Advanced. Choose \"Accept the Risk and Continue\". If you are using Google Chrome, you can bypass the error message by typing in \"thisisunsafe\" or clicking on the \"Proceed to 192.168.252.2 (unsafe)\" link.","title":"Available Ports"},{"location":"wxd-reference-ports/#watsonxdata-and-demonstration-ports","text":"The top of your TechZone reservation will contain two published services at the top of the details page. These URLs and Port numbers are needed to access the demo. The list will contain the following information: IBM watsonx.data and Milvus Demo: http://region.services.cloud.techzone.ibm.com:33333 Watsonx UI: https://region.services.cloud.techzone.ibm.com:41311 The server URL will be different for each region and data center that your machine is provisioned on. The server name is usually in the format: region.services.cloud.techzone.ibm.com:port The port number that is provided in the reservation is mapped to the proper port number in the server. These links may result in a Certificate error in Firefox. Follow these steps to ignore the error when accessing these URLs. Select Advanced. Choose \"Accept the Risk and Continue\". If you are using Google Chrome, you can bypass the error message by typing in \"thisisunsafe\" or clicking on the \"Proceed to 192.168.252.2 (unsafe)\" link.","title":"Watsonx.data and Demonstration Ports"},{"location":"wxd-reference-techzone/","text":"Requesting a TechZone image Log into TechZone ( https://techzone.ibm.com ) and search for the watsonx.data Developer Base Image or use the following link. https://techzone.ibm.com/collection/ibm-watsonxdata-developer-base-image If you have not logged into the IBM Cloud site, you will be asked to authenticate with your IBM userid. If you do not have an IBM userid, you will need to register for one. This lab is open to IBMers and Business Partners. Once you have logged in, you should see the following. Select the Environment tab on the far-left side and then choose the IBM watsonx.data and Milvus Demonstration. Press the Reserve button. Select \"reserve now\" (why wait?). For \"Purpose\" select Self Education. This will expand to request additional information. Fill in the purpose field with something meaningful (watsonx.data education). Next select preferred Geography for the image. Choose any of the regions that are closest to your location. Note : The TechZone scheduler will pick a location in your region that has capacity to deploy your image. The number of locations has expanded to 5 North American, 6 European and 4 AP locations which will hopefully provide capacity to deploy the lab. If you find that your reservation is not being provisioned, check the status of the TechZone environment by referring to the TechZone status page at https://techzone.status.io . Next select the end date for the lab. Make sure you select enough time for you to use the lab! It defaults to 2 days, but you can extend the reservation! You do not need to enable VPN Access . Once you have completed the form, check the box indicating that you agree to the terms and conditions of using TechZone, and click SUBMIT on the bottom right-hand corner. At this point you will need to wait patiently for an email that acknowledges that your request has been placed into Provisioning mode. Eventually you will receive an email confirming that the system is ready to be used. Note that this can take a number of hours depending on the load on the TechZone servers. If your reservation failed because of capacity constraints, you may want to check the status of TechZone first ( https://techzone.status.io ) before attending to reserve another instance. If the systems appear to be okay, try requesting another image or using a different server location if possible. Contact TechZone support if you are having difficulties provisioning a system.","title":"Requesting an image"},{"location":"wxd-reference-techzone/#requesting-a-techzone-image","text":"Log into TechZone ( https://techzone.ibm.com ) and search for the watsonx.data Developer Base Image or use the following link. https://techzone.ibm.com/collection/ibm-watsonxdata-developer-base-image If you have not logged into the IBM Cloud site, you will be asked to authenticate with your IBM userid. If you do not have an IBM userid, you will need to register for one. This lab is open to IBMers and Business Partners. Once you have logged in, you should see the following. Select the Environment tab on the far-left side and then choose the IBM watsonx.data and Milvus Demonstration. Press the Reserve button. Select \"reserve now\" (why wait?). For \"Purpose\" select Self Education. This will expand to request additional information. Fill in the purpose field with something meaningful (watsonx.data education). Next select preferred Geography for the image. Choose any of the regions that are closest to your location. Note : The TechZone scheduler will pick a location in your region that has capacity to deploy your image. The number of locations has expanded to 5 North American, 6 European and 4 AP locations which will hopefully provide capacity to deploy the lab. If you find that your reservation is not being provisioned, check the status of the TechZone environment by referring to the TechZone status page at https://techzone.status.io . Next select the end date for the lab. Make sure you select enough time for you to use the lab! It defaults to 2 days, but you can extend the reservation! You do not need to enable VPN Access . Once you have completed the form, check the box indicating that you agree to the terms and conditions of using TechZone, and click SUBMIT on the bottom right-hand corner. At this point you will need to wait patiently for an email that acknowledges that your request has been placed into Provisioning mode. Eventually you will receive an email confirming that the system is ready to be used. Note that this can take a number of hours depending on the load on the TechZone servers. If your reservation failed because of capacity constraints, you may want to check the status of TechZone first ( https://techzone.status.io ) before attending to reserve another instance. If the systems appear to be okay, try requesting another image or using a different server location if possible. Contact TechZone support if you are having difficulties provisioning a system.","title":"Requesting a TechZone image"}]}